import cv2
import numpy as np
import threading
import queue
import time
import json
from pathlib import Path

from detector.detector_manager import ByteTrackDetectorManager
from reid.reid_manager import GlobalReIDManager
from reid.redis_handler import FeatureStoreRedisHandler
from reid.similarity import FeatureSimilarityCalculator
from config import settings
from image_processor import ImageProcessor
from result.performance_logger import PerformanceLogger

from ppe_detector import PPEDetector
from homography_manager import HomographyManager
from backend_client import BackendClient
from models.mapping.point_transformer import transform_point


class IntegratedTrackingSystem:
    """
    ReID ê¸°ëŠ¥ê³¼ í˜¸ëª¨ê·¸ë˜í”¼ ê¸°ëŠ¥, PPE íƒì§€ ê¸°ëŠ¥ì„ í†µí•©í•œ ê°ì²´ ì¶”ì  ì‹œìŠ¤í…œ
    ë‘ ê°œì˜ ì˜ìƒì—ì„œ ê°ì²´ ì¶”ì ì´ ì˜ ë˜ë„ë¡ í˜¸ëª¨ê·¸ë˜í”¼ ì¢Œí‘œë¥¼ ì§ì ‘ ì…ë ¥í•˜ëŠ” ë°©ì‹
    """
    
    def __init__(self, video_paths=None, model_path=None, tracker_config=None, 
                 redis_conf=None, reid_conf=None, calibration_files=None, backend_url=None,
                 ppe_model_path=None):
        # ì„¤ì • ë¡œë“œ
        self.model_path = model_path or settings.YOLO_MODEL_PATH
        self.tracker_config = tracker_config or settings.TRACKER_CONFIG
        redis_conf = redis_conf or settings.REDIS_CONFIG
        reid_conf = reid_conf or settings.REID_CONFIG
        
        # ë¹„ë””ì˜¤ ê²½ë¡œ ì„¤ì •
        self.video_paths = video_paths or settings.VIDEO_INPUT_PATHS
        
        # í˜¸ëª¨ê·¸ë˜í”¼ ë§¤ë‹ˆì € ì´ˆê¸°í™”
        self.homography_manager = HomographyManager()
        
        # PPE íƒì§€ê¸° ì´ˆê¸°í™”
        self.ppe_detector = PPEDetector(ppe_model_path or "models/weights/best_yolo11n.pt")
        
        # ìº˜ë¦¬ë¸Œë ˆì´ì…˜ íŒŒì¼ ë¡œë“œ (ëª…ë ¹í–‰ ì¸ì ìš°ì„ , ì—†ìœ¼ë©´ settingsì—ì„œ ìë™ ë¡œë“œ)
        if calibration_files:
            for camera_id, calib_file in calibration_files.items():
                self.homography_manager.add_camera_calibration(camera_id, calib_file)
        else:
            # settings.pyì—ì„œ ìë™ìœ¼ë¡œ í˜¸ëª¨ê·¸ë˜í”¼ ë§¤íŠ¸ë¦­ìŠ¤ ë¡œë“œ
            for camera_id, matrix in settings.HOMOGRAPHY_MATRICES.items():
                self.homography_manager.homography_matrices[camera_id] = np.array(matrix)
                print(f"Camera {camera_id} homography matrix loaded from settings")
        
        # ë°±ì—”ë“œ í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
        self.backend_client = BackendClient(backend_url or "http://localhost:5000")
        
        # Redis í•¸ë“¤ëŸ¬ ì´ˆê¸°í™”
        redis_handler = FeatureStoreRedisHandler(
            redis_host=redis_conf.get("host", "localhost"),
            redis_port=redis_conf.get("port", 6379)
        )
        similarity = FeatureSimilarityCalculator()
        self.reid = GlobalReIDManager(redis_handler, similarity, similarity_threshold=reid_conf.get("threshold", 0.7))
        
        # ë¡œì»¬ IDì™€ ê¸€ë¡œë²Œ ID ë§¤í•‘ ì €ì¥ì†Œ
        self.local_to_global_mapping = {}
        
        # ImageProcessor ì´ˆê¸°í™”
        self.image_processor = ImageProcessor()
        
        # ìŠ¤ë ˆë“œë³„ ì„±ëŠ¥ ë¡œê±° ì €ì¥ì†Œ
        self.thread_performance_loggers = {}
        
        # ì¶”ì  ê²°ê³¼ ì €ì¥ì†Œ
        self.tracking_results = {}
        
        # PPE ìœ„ë°˜ ì¶”ì  ì €ì¥ì†Œ (ì¤‘ë³µ ì „ì†¡ ë°©ì§€)
        self.ppe_violation_history = {}
        
        print("Integrated Tracking System initialized")
        print(f"Videos: {self.video_paths}")
        print(f"Model: {self.model_path}")
        print(f"PPE Model: {ppe_model_path or 'models/weights/best_yolo11n.pt'}")
        print(f"Backend URL: {backend_url or 'http://localhost:5000'}")
        
        # ë¡œë“œëœ í˜¸ëª¨ê·¸ë˜í”¼ ë§¤íŠ¸ë¦­ìŠ¤ ì •ë³´ ì¶œë ¥
        print(f"Loaded homography matrices for cameras: {list(self.homography_manager.homography_matrices.keys())}")
        for camera_id in self.homography_manager.homography_matrices.keys():
            print(f"  Camera {camera_id}: Matrix shape {self.homography_manager.homography_matrices[camera_id].shape}")
    
    def create_detector_for_thread(self):
        """ìŠ¤ë ˆë“œë³„ ë…ë¦½ì ì¸ detector ìƒì„±"""
        return ByteTrackDetectorManager(self.model_path, self.tracker_config)
    
    def process_frame_with_reid_and_homography(self, frame, frame_id, camera_id, detector):
        """ReIDì™€ í˜¸ëª¨ê·¸ë˜í”¼ë¥¼ í†µí•©í•œ í”„ë ˆì„ ì²˜ë¦¬"""
        # ì„±ëŠ¥ ì¸¡ì • ì‹œì‘
        if camera_id not in self.thread_performance_loggers:
            self.thread_performance_loggers[camera_id] = PerformanceLogger(output_dir=f"result/camera_{camera_id}")
        
        logger = self.thread_performance_loggers[camera_id]
        logger.start_frame_timing(frame_id, camera_id)
        
        # ê¸€ë¡œë²Œ ReID ë§¤ë‹ˆì € í”„ë ˆì„ ì—…ë°ì´íŠ¸
        self.reid.update_frame(frame_id)
        
        # íƒì§€ ë° íŠ¸ë˜í‚¹
        logger.start_detection_timing()
        logger.start_tracking_timing()
        
        track_list = detector.detect_and_track(frame, frame_id)
        
        logger.end_detection_timing()
        logger.end_tracking_timing()
        
        # í”„ë ˆì„ë³„ ë§¤ì¹­ëœ íŠ¸ë™ ì¶”ì 
        frame_matched_tracks = set()
        frame_detections = []
        frame_violations = []
        
        # ê°ì²´ ìˆ˜ ì„¤ì •
        logger.set_object_count(len(track_list))
        
        for track in track_list:
            local_id = track["track_id"]
            bbox = track["bbox"]
            
            # Feature ì¶”ì¶œ
            crop, feature = self.image_processor.process_track_for_reid(frame, track)
            
            # ReID ë§¤ì¹­
            camera_key = f"{camera_id}_{local_id}"
            if camera_key in self.local_to_global_mapping:
                # ê¸°ì¡´ ë§¤í•‘ ì‚¬ìš©
                global_id = self.local_to_global_mapping[camera_key]
                logger.start_same_camera_reid_timing()
                
                self.reid._update_track_camera(
                    global_id, feature, bbox, str(camera_id), frame_id, local_id
                )
                
                logger.end_same_camera_reid_timing()
            else:
                # ìƒˆë¡œìš´ ReID ë§¤ì¹­
                logger.start_cross_camera_reid_timing()
                
                global_id = self.reid.match_or_create(
                    features=feature,
                    bbox=bbox,
                    camera_id=str(camera_id),
                    frame_id=frame_id,
                    frame_shape=frame.shape[:2],
                    matched_tracks=frame_matched_tracks,
                    local_track_id=local_id
                )
                
                logger.end_cross_camera_reid_timing()
                
                if global_id is None:
                    global_id = local_id
                else:
                    self.local_to_global_mapping[camera_key] = global_id
            
            # ì¢Œí‘œ ë³€í™˜
            x1, y1, x2, y2, point_x, point_y = self.image_processor.get_bbox_coordinates(bbox)
            
            # í˜¸ëª¨ê·¸ë˜í”¼ ë³€í™˜ (point_transformer ì‚¬ìš©)
            try:
                homography_matrix = np.array(settings.HOMOGRAPHY_MATRICES[camera_id])
                real_x, real_y = transform_point(point_x, point_y, homography_matrix)
            except Exception as e:
                print(f"Error in coordinate transformation for camera {camera_id}: {e}")
                real_x, real_y = 0, 0
            
            # PPE ìœ„ë°˜ íƒì§€
            ppe_violations = self.ppe_detector.detect_ppe_violations(frame, bbox)
            
            # PPE ìœ„ë°˜ì´ ìˆìœ¼ë©´ ìœ„ë°˜ ë°ì´í„° ìƒì„±
            if ppe_violations:
                violation_key = f"{camera_id}_{global_id}_{frame_id}"
                if violation_key not in self.ppe_violation_history:
                    self.ppe_violation_history[violation_key] = True
                    
                    violation_data = {
                        "worker_id": f"W{global_id:03d}",
                        "zone_id": f"Z{camera_id:02d}",
                        "timestamp": time.strftime("%Y-%m-%d %H:%M:%S"),
                        "violations": {
                            "ppe": [v['type'] for v in ppe_violations],
                            "roi": []
                        }
                    }
                    frame_violations.append(violation_data)
                    
                    print(f"[PPE VIOLATION] Worker {global_id} in Camera {camera_id}: {[v['type'] for v in ppe_violations]}")
            
            # ê²°ê³¼ ì €ì¥
            detection_data = {
                "cameraID": int(camera_id),
                "workerID": int(global_id),
                "position_X": real_x,
                "position_Y": real_y,
                "frame_id": frame_id,
                "local_id": local_id,
                "bbox": [x1, y1, x2, y2],
                "image_coords": [point_x, point_y],
                "ppe_violations": [v['type'] for v in ppe_violations] if ppe_violations else []
            }
            frame_detections.append(detection_data)
            
            # ë°”ìš´ë”© ë°•ìŠ¤ ê·¸ë¦¬ê¸°
            color = (0, 0, 255) if ppe_violations else (0, 255, 0)  # ìœ„ë°˜ì‹œ ë¹¨ê°„ìƒ‰, ì •ìƒì‹œ ì´ˆë¡ìƒ‰
            cv2.rectangle(frame, (x1, y1), (x2, y2), color, 2)
            cv2.putText(frame, f'ID:{global_id}', (x1, y1 - 10), 
                       cv2.FONT_HERSHEY_SIMPLEX, 0.8, color, 2)
            
            # ì¢Œí‘œ ì •ë³´ í‘œì‹œ
            coord_text = f"({real_x:.1f}, {real_y:.1f})"
            cv2.putText(frame, coord_text, (x1, y2 + 15), 
                       cv2.FONT_HERSHEY_SIMPLEX, 0.4, (0, 0, 255), 1)
            
            # PPE ìœ„ë°˜ ì •ë³´ í‘œì‹œ
            if ppe_violations:
                violation_text = f"PPE: {', '.join([v['type'] for v in ppe_violations])}"
                cv2.putText(frame, violation_text, (x1, y2 + 30), 
                           cv2.FONT_HERSHEY_SIMPLEX, 0.4, (0, 0, 255), 1)
        
        # ì„±ëŠ¥ ë°ì´í„° ë¡œê¹…
        logger.log_frame_performance()
        
        return frame, frame_detections, frame_violations
    
    def send_detections_to_backend(self, detections, violations):
        """ê°ì§€ ê²°ê³¼ì™€ ìœ„ë°˜ ê²°ê³¼ë¥¼ ë°±ì—”ë“œë¡œ ì „ì†¡"""
        # ì›Œì»¤ ë°ì´í„° ì „ì†¡
        if detections:
            worker_data = {
                "timestamp": time.strftime("%Y-%m-%d %H:%M:%S"),
                "workers": []
            }
            
            for det in detections:
                # NumPy íƒ€ì…ì„ Python ê¸°ë³¸ íƒ€ì…ìœ¼ë¡œ ë³€í™˜
                worker_info = {
                    "worker_id": str(det["workerID"]),
                    "zone_id": f"Z{det['cameraID']:02d}",
                    "x": float(det["position_X"]),  # float32ë¥¼ floatë¡œ ë³€í™˜
                    "y": float(det["position_Y"]),  # float32ë¥¼ floatë¡œ ë³€í™˜
                    "product_count": 0,
                    "timestamp": time.strftime("%Y-%m-%d %H:%M:%S")
                }
                worker_data["workers"].append(worker_info)
            
            # ë°±ì—”ë“œë¡œ ì „ì†¡
            self.backend_client.send_worker_data(worker_data)
        
        # ìœ„ë°˜ ë°ì´í„° ì „ì†¡
        if violations:
            violation_data = {
                "timestamp": time.strftime("%Y-%m-%d %H:%M:%S"),
                "violations": []
            }
            
            for violation in violations:
                violation_entry = {
                    "worker_id": str(violation["worker_id"]),
                    "zone_id": str(violation["zone_id"]),
                    "timestamp": str(violation["timestamp"]),
                    "violations": violation["violations"]
                }
                violation_data["violations"].append(violation_entry)
            
            # ë°±ì—”ë“œë¡œ ì „ì†¡
            self.backend_client.send_violation_data(violation_data)
    
    def run_video_thread(self, video_path, camera_id, frame_buffer, sync_event, stop_event):
        """ë¹„ë””ì˜¤ ì²˜ë¦¬ ìŠ¤ë ˆë“œ"""
        detector = self.create_detector_for_thread()
        
        cap = cv2.VideoCapture(video_path)
        frame_id = 0
        processed_frame_id = 0
        
        # í”„ë ˆì„ ìŠ¤í‚µ ì„¤ì •
        target_fps = 30
        frame_skip = 30/target_fps
        
        while cap.isOpened() and not stop_event.is_set():
            ret, frame = cap.read()
            if not ret:
                print(f"[{video_path}] Video ended")
                break
            
            frame_id += 1
            
            # í”„ë ˆì„ ìŠ¤í‚µ
            if frame_id % frame_skip != 0:
                continue
            
            processed_frame_id += 1
            
            # í”„ë ˆì„ ì²˜ë¦¬
            processed_frame, detections, violations = self.process_frame_with_reid_and_homography(
                frame, processed_frame_id, camera_id, detector
            )
            
            # ë°±ì—”ë“œë¡œ ì „ì†¡
            self.send_detections_to_backend(detections, violations)
            
            # ê²°ê³¼ ì €ì¥
            frame_data = {
                'video_path': video_path,
                'frame': processed_frame,
                'detections': detections,
                'violations': violations,
                'frame_id': processed_frame_id
            }
            
            # ë²„í¼ì— ì €ì¥
            frame_buffer.put(frame_data)
            
            # ë™ê¸°í™” ëŒ€ê¸°
            sync_event.wait(0.1)
            sync_event.clear()
        
        cap.release()
        frame_buffer.put({'video_path': video_path, 'frame': None, 'detections': None, 'violations': None, 'frame_id': -1})
    
    def run_multi_video_tracking(self):
        """ë©€í‹° ë¹„ë””ì˜¤ í†µí•© ì¶”ì  ì‹¤í–‰"""
        stop_event = threading.Event()
        sync_event = threading.Event()
        
        # ê° ë¹„ë””ì˜¤ë³„ í”„ë ˆì„ ë²„í¼
        frame_buffers = {video_path: queue.Queue(maxsize=1) for video_path in self.video_paths}
        
        # í”„ë ˆì„ ìˆ˜ì§‘ ìŠ¤ë ˆë“œ ìƒì„±
        collector_threads = []
        for i, video_path in enumerate(self.video_paths):
            thread = threading.Thread(
                target=self.run_video_thread,
                args=(video_path, i, frame_buffers[video_path], sync_event, stop_event),
                daemon=True
            )
            collector_threads.append(thread)
            thread.start()
        
        # ë™ê¸°í™”ëœ í”„ë ˆì„ ì²˜ë¦¬
        active_videos = set(self.video_paths)
        latest_detections = {}
        latest_violations = {}
        frame_count = 0
        max_frames = 3000
        
        while active_videos and frame_count < max_frames:
            # ëª¨ë“  ë¹„ë””ì˜¤ì—ì„œ í”„ë ˆì„ì´ ì¤€ë¹„ë  ë•Œê¹Œì§€ ëŒ€ê¸°
            all_frames_ready = True
            current_frames = {}
            
            for video_path in active_videos.copy():
                try:
                    frame_data = frame_buffers[video_path].get(timeout=0.01)
                    
                    if frame_data['frame'] is None:
                        active_videos.discard(video_path)
                        if video_path in latest_detections:
                            del latest_detections[video_path]
                        if video_path in latest_violations:
                            del latest_violations[video_path]
                        continue
                    
                    current_frames[video_path] = frame_data
                    
                except queue.Empty:
                    all_frames_ready = False
                    break
            
            if not all_frames_ready:
                time.sleep(0.01)
                continue
            
            # ëª¨ë“  í”„ë ˆì„ì´ ì¤€ë¹„ë˜ì—ˆìœ¼ë©´ ë™ì‹œì— ì²˜ë¦¬
            frame_count += 1
            print(f"[SYNC] Processing frame {frame_count} for all videos")
            
            # ëª¨ë“  ì¹´ë©”ë¼ì˜ ê°ì§€ ê²°ê³¼ ìˆ˜ì§‘
            all_detections = []
            all_violations = []
            
            for video_path, frame_data in current_frames.items():
                detections = frame_data['detections']
                violations = frame_data['violations']
                
                if detections:
                    latest_detections[video_path] = detections
                    all_detections.extend(detections)
                
                if violations:
                    latest_violations[video_path] = violations
                    all_violations.extend(violations)
            
            # ëª¨ë“  ìŠ¤ë ˆë“œì—ê²Œ ë‹¤ìŒ í”„ë ˆì„ ì²˜ë¦¬ í—ˆê°€ ì‹ í˜¸ ì „ì†¡
            sync_event.set()
        
        # ìŠ¤ë ˆë“œ ì •ë¦¬
        stop_event.set()
        for thread in collector_threads:
            thread.join(timeout=1.0)
        
        return all_detections, all_violations
    
    def save_tracking_results(self, output_file="tracking_results.json"):
        """ì¶”ì  ê²°ê³¼ ì €ì¥"""
        results = {
            "timestamp": time.strftime("%Y-%m-%d %H:%M:%S"),
            "videos": self.video_paths,
            "model": self.model_path,
            "ppe_model": self.ppe_detector.model_path,
            "total_detections": len(self.tracking_results),
            "results": self.tracking_results
        }
        
        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(results, f, indent=2, ensure_ascii=False)
        
        print(f"Tracking results saved to: {output_file}")
    
    def print_performance_summary(self):
        """ì„±ëŠ¥ ìš”ì•½ ì¶œë ¥"""
        print("\n" + "="*60)
        print("ğŸ“Š INTEGRATED TRACKING PERFORMANCE SUMMARY")
        print("="*60)
        
        for camera_id, thread_logger in self.thread_performance_loggers.items():
            print(f"\nğŸ“Š Camera {camera_id} Performance Summary:")
            thread_logger.print_summary()
        
        print("="*60)

