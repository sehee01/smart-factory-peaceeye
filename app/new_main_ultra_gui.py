import argparse
import sys
from pathlib import Path

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ê²½ë¡œ ì„¤ì •
PROJECT_ROOT = Path(__file__).resolve().parent.parent
EXTRA_PATHS = [
    str(PROJECT_ROOT),                      # ë£¨íŠ¸ ìì²´ (app, frontend ë“± import ê°€ëŠ¥)
    str(PROJECT_ROOT / "deep-person-reid-master"),  # í•„ìš”í•œ ê²½ìš°ë§Œ
    str(PROJECT_ROOT / "app" / "models" / "mapping"),   # point_transformer ê²½ë¡œ ìˆ˜ì •
]

for p in EXTRA_PATHS:
    if p not in sys.path:
        sys.path.insert(0, p)

# np.float í˜¸í™˜ì„± ë¬¸ì œ í•´ê²°
import numpy as np
if not hasattr(np, 'float'):
    np.float = float

import cv2
import time
import threading
from config import settings
from integrated_tracking_system_ultra import IntegratedTrackingSystemUltra


class GUIVideoProcessor:
    """GUI í™”ë©´ì„ í‘œì‹œí•˜ëŠ” ë¹„ë””ì˜¤ ì²˜ë¦¬ í´ë˜ìŠ¤"""
    
    def __init__(self, tracking_system):
        self.tracking_system = tracking_system
        self.video_paths = tracking_system.video_paths
        self.stop_event = threading.Event()
        self.detectors = {}
        
        # GUI ì„¤ì •
        self.window_names = []
        self.video_windows = {}
        
        # ì„±ëŠ¥ ì¸¡ì •
        self.fps_counters = {}
        self.frame_times = {}
        
    def create_detector_for_thread(self, camera_id):
        """ìŠ¤ë ˆë“œë³„ ë…ë¦½ì ì¸ detector ìƒì„±"""
        if camera_id not in self.detectors:
            self.detectors[camera_id] = self.tracking_system.create_detector_for_thread()
        return self.detectors[camera_id]
    
    def process_video_thread(self, video_path, camera_id):
        """ë¹„ë””ì˜¤ ì²˜ë¦¬ ìŠ¤ë ˆë“œ (GUI í‘œì‹œìš©)"""
        try:
            detector = self.create_detector_for_thread(camera_id)
            
            cap = cv2.VideoCapture(video_path)
            if not cap.isOpened():
                print(f"âŒ Could not open video: {video_path}")
                return
            
            # ìœˆë„ìš° ìƒì„±
            window_name = f"Camera {camera_id} - {Path(video_path).name}"
            cv2.namedWindow(window_name, cv2.WINDOW_NORMAL)
            cv2.resizeWindow(window_name, 1920, 1080)
            self.window_names.append(window_name)
            
            frame_id = 0
            start_time = time.time()
            
            print(f"ğŸ¥ Started processing Camera {camera_id}: {video_path}")
            
            while cap.isOpened() and not self.stop_event.is_set():
                ret, frame = cap.read()
                if not ret:
                    print(f"ğŸ“¹ Camera {camera_id} video ended")
                    break
                
                frame_id += 1
                
                # í”„ë ˆì„ ìŠ¤í‚µ (ì„±ëŠ¥ í–¥ìƒ)
                if frame_id % 2 != 0:  # 2í”„ë ˆì„ë§ˆë‹¤ ì²˜ë¦¬
                    continue
                
                # ì²˜ë¦¬ ì‹œê°„ ì¸¡ì •
                frame_start_time = time.time()
                
                # í”„ë ˆì„ ì²˜ë¦¬ (ReID, í˜¸ëª¨ê·¸ë˜í”¼, PPE í¬í•¨)
                processed_frame, detections, violations = self.tracking_system.process_frame_with_reid_and_homography(
                    frame, frame_id, camera_id, detector
                )
                
                # FPS ê³„ì‚°
                frame_time = time.time() - frame_start_time
                if camera_id not in self.fps_counters:
                    self.fps_counters[camera_id] = []
                self.fps_counters[camera_id].append(frame_time)
                
                # ìµœê·¼ 30í”„ë ˆì„ì˜ í‰ê·  FPS ê³„ì‚°
                if len(self.fps_counters[camera_id]) > 30:
                    self.fps_counters[camera_id] = self.fps_counters[camera_id][-30:]
                
                avg_fps = 1.0 / (sum(self.fps_counters[camera_id]) / len(self.fps_counters[camera_id])) if self.fps_counters[camera_id] else 0
                
                # GUI ì •ë³´ ì¶”ê°€
                self.add_gui_info(processed_frame, camera_id, frame_id, len(detections), avg_fps, violations)
                
                # í™”ë©´ì— í‘œì‹œ
                cv2.imshow(window_name, processed_frame)
                
                # í‚¤ ì…ë ¥ ì²˜ë¦¬
                key = cv2.waitKey(1) & 0xFF
                if key == ord('q'):
                    self.stop_event.set()
                    break
                elif key == ord('s'):  # ìŠ¤í¬ë¦°ìƒ· ì €ì¥
                    screenshot_path = f"screenshot_camera_{camera_id}_{frame_id}.jpg"
                    cv2.imwrite(screenshot_path, processed_frame)
                    print(f"ğŸ“¸ Screenshot saved: {screenshot_path}")
            
            cap.release()
            print(f"âœ… Camera {camera_id} processing completed")
            
        except Exception as e:
            print(f"âŒ Error in camera {camera_id} processing: {e}")
            import traceback
            traceback.print_exc()
    
    def add_gui_info(self, frame, camera_id, frame_id, detection_count, fps, violations):
        """GUIì— ì •ë³´ ì¶”ê°€"""
        # ë°°ê²½ ì •ë³´ íŒ¨ë„
        cv2.rectangle(frame, (10, 10), (400, 120), (0, 0, 0), -1)
        cv2.rectangle(frame, (10, 10), (400, 120), (255, 255, 255), 2)
        
        # ì •ë³´ í…ìŠ¤íŠ¸
        info_lines = [
            f"Camera: {camera_id}",
            f"Frame: {frame_id}",
            f"Detections: {detection_count}",
            f"FPS: {fps:.1f}",
            f"PPE Violations: {len(violations)}"
        ]
        
        for i, line in enumerate(info_lines):
            y_pos = 35 + i * 18
            cv2.putText(frame, line, (20, y_pos), 
                       cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 2)
        
        # PPE ìœ„ë°˜ ì•Œë¦¼
        if violations:
            cv2.rectangle(frame, (10, 130), (400, 160), (0, 0, 255), -1)
            cv2.putText(frame, f"PPE VIOLATION DETECTED!", (20, 150), 
                       cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)
    
    def run_multi_video_gui(self):
        """ë©€í‹° ë¹„ë””ì˜¤ GUI ì‹¤í–‰"""
        print("ğŸš€ Starting Multi-Video GUI Processing...")
        print(f"ğŸ“¹ Processing {len(self.video_paths)} videos")
        
        # ê° ë¹„ë””ì˜¤ë³„ ìŠ¤ë ˆë“œ ìƒì„±
        threads = []
        for i, video_path in enumerate(self.video_paths):
            thread = threading.Thread(
                target=self.process_video_thread,
                args=(video_path, i),
                daemon=True
            )
            threads.append(thread)
            thread.start()
        
        try:
            # ë©”ì¸ ë£¨í”„ (í‚¤ ì…ë ¥ ì²˜ë¦¬)
            while not self.stop_event.is_set():
                # í‚¤ ì…ë ¥ í™•ì¸
                key = cv2.waitKey(1) & 0xFF
                if key == ord('q'):
                    print("ğŸ›‘ Quit requested by user")
                    break
                
                # ëª¨ë“  ìœˆë„ìš°ê°€ ë‹«í˜”ëŠ”ì§€ í™•ì¸ (ì•ˆì „í•˜ê²Œ)
                try:
                    if self.window_names and cv2.getWindowProperty(self.window_names[0], cv2.WND_PROP_VISIBLE) < 1:
                        print("ğŸ›‘ Window closed by user")
                        break
                except:
                    pass  # ìœˆë„ìš°ê°€ ì•„ì§ ìƒì„±ë˜ì§€ ì•Šì•˜ì„ ìˆ˜ ìˆìŒ
                
                time.sleep(0.1)
                
        except KeyboardInterrupt:
            print("\nâš ï¸ Interrupted by user")
        finally:
            # ì •ë¦¬
            self.stop_event.set()
            for thread in threads:
                thread.join(timeout=1.0)
            
            cv2.destroyAllWindows()
            print("âœ… GUI processing completed")


def main():
    """GUI ë²„ì „ ë©”ì¸ í•¨ìˆ˜"""
    parser = argparse.ArgumentParser(
        description="Integrated ReID, Homography, and PPE Tracking System with GUI (Ultralytics)"
    )
    parser.add_argument(
        '--videos',
        nargs='+',
        type=str,
        default=settings.VIDEO_INPUT_PATHS,
        help='List of video file paths.'
    )
    parser.add_argument(
        '--yolo_model',
        type=str,
        default="models/weights/bestcctv.pt",
        help='Path to the YOLOv8 model file for person detection.'
    )
    parser.add_argument(
        '--ppe_model',
        type=str,
        default="models/weights/best_yolo11n.pt",
        help='Path to the PPE detection model file.'
    )
    parser.add_argument(
        '--calibration_files',
        nargs='+',
        type=str,
        help='List of calibration files for each camera (in order).'
    )
    parser.add_argument(
        '--redis_host',
        type=str,
        default="localhost",
        help='Redis server host.'
    )
    parser.add_argument(
        '--redis_port',
        type=int,
        default=6379,
        help='Redis server port.'
    )
    args = parser.parse_args()
    
    # ìº˜ë¦¬ë¸Œë ˆì´ì…˜ íŒŒì¼ ë§¤í•‘
    calibration_files = {}
    if args.calibration_files:
        for i, calib_file in enumerate(args.calibration_files):
            calibration_files[i] = calib_file
    else:
        print("No calibration files specified. Using homography matrices from settings.py")
    
    # ì‹œìŠ¤í…œ ì´ˆê¸°í™”
    tracker_config = settings.TRACKER_CONFIG
    reid_config = settings.REID_CONFIG
    
    redis_conf = {
        "host": args.redis_host,
        "port": args.redis_port,
        "camera_id": "camera_0"
    }
    
    # Ultralytics ê¸°ë°˜ í†µí•© ì¶”ì  ì‹œìŠ¤í…œ ìƒì„±
    tracking_system = IntegratedTrackingSystemUltra(
        video_paths=args.videos,
        model_path=args.yolo_model,
        tracker_config=tracker_config,
        redis_conf=redis_conf,
        reid_conf=reid_config,
        calibration_files=calibration_files,
        backend_url=None,  # ë°±ì—”ë“œ ì „ì†¡ ë¹„í™œì„±í™”
        ppe_model_path=args.ppe_model
    )
    
    print(f"â–¶ Processing {len(args.videos)} videos with GUI display")
    for i, video_path in enumerate(args.videos):
        print(f"  Camera {i}: {video_path}")
        if i in calibration_files:
            print(f"    Calibration: {calibration_files[i]}")
        else:
            print(f"    Homography: Loaded from settings.py")
    
    # GUI ë¹„ë””ì˜¤ í”„ë¡œì„¸ì„œ ìƒì„± ë° ì‹¤í–‰
    gui_processor = GUIVideoProcessor(tracking_system)
    gui_processor.run_multi_video_gui()
    
    print("ğŸ‰ GUI processing completed!")


if __name__ == '__main__':
    main()
