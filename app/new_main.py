import cv2
import numpy as np
from pathlib import Path
import sys
import torch
from scipy.spatial.distance import cdist
import threading
import queue
import argparse
import time
import json
import requests
from result.performance_logger import PerformanceLogger
from datetime import datetime

PROJECT_ROOT = Path(__file__).resolve().parent.parent
EXTRA_PATHS = [
    str(PROJECT_ROOT),                      # ë£¨íŠ¸ ìì²´ (app, ByteTrack, frontend ë“± import ê°€ëŠ¥)
    str(PROJECT_ROOT / "ByteTrack"),        # ByteTrack ì§ì ‘ ì°¸ì¡°ê°€ í•„ìš”í•œ ê²½ìš°
    str(PROJECT_ROOT / "deep-person-reid-master"),  # í•„ìš”í•œ ê²½ìš°ë§Œ
    str(PROJECT_ROOT / "app" / "models" / "mapping"),   # point_transformer ê²½ë¡œ ìˆ˜ì •
]

for p in EXTRA_PATHS:
    if p not in sys.path:
        sys.path.insert(0, p)

# np.float í˜¸í™˜ì„± ë¬¸ì œ í•´ê²°
if not hasattr(np, 'float'):
    np.float = float

from detector.detector_manager import ByteTrackDetectorManager
from reid.reid_manager import GlobalReIDManager
from reid.redis_handler import FeatureStoreRedisHandler
from reid.similarity import FeatureSimilarityCalculator
from config import settings
from models.mapping.point_transformer import transform_point
from image_processor import ImageProcessor


class HomographyManager:
    """í˜¸ëª¨ê·¸ë˜í”¼ ë§¤íŠ¸ë¦­ìŠ¤ ê´€ë¦¬ í´ë˜ìŠ¤"""
    
    def __init__(self):
        self.homography_matrices = {}
        self.calibration_data = {}
        # Unity ë§µ ì¢Œí‘œê³„ ì„¤ì • (4ê°œ ì¢Œí‘œ ë°©ì‹)
        self.unity_map_corners = {
            0: [  # ì¹´ë©”ë¼ 0 (ë³µë„) - ì™¼ìª½ ìƒë‹¨ë¶€í„° ì‹œê³„ë°©í–¥
                {"x": 3700, "y": -4088},      # ì™¼ìª½ ìƒë‹¨
                {"x": 3700, "y": -1700},    # ì˜¤ë¥¸ìª½ ìƒë‹¨
                {"x": 10700, "y": 1080},   # ì˜¤ë¥¸ìª½ í•˜ë‹¨
                {"x": 10700, "y": -8700}      # ì™¼ìª½ í•˜ë‹¨
            ],
            1: [  # ì¹´ë©”ë¼ 1 (ë°©) - ì™¼ìª½ ìƒë‹¨ë¶€í„° ì‹œê³„ë°©í–¥
                {"x": 5439, "y": -770},    # ì™¼ìª½ ìƒë‹¨
                {"x": 4000, "y": -1350},    # ì˜¤ë¥¸ìª½ ìƒë‹¨
                {"x": 3220, "y": 408},  # ì˜¤ë¥¸ìª½ í•˜ë‹¨
                {"x": 4606, "y": 903}   # ì™¼ìª½ í•˜ë‹¨
            ]
        }
    
    def set_unity_map_corners(self, camera_id, corners):
        """Unity ë§µì—ì„œ ê° ì¹´ë©”ë¼ ì˜ì—­ì˜ 4ê°œ ëª¨ì„œë¦¬ ì¢Œí‘œ ì„¤ì •
        corners: [ì™¼ìª½ìƒë‹¨, ì˜¤ë¥¸ìª½ìƒë‹¨, ì˜¤ë¥¸ìª½í•˜ë‹¨, ì™¼ìª½í•˜ë‹¨] ìˆœì„œ
        """
        if len(corners) != 4:
            print(f"Error: Need exactly 4 corners for camera {camera_id}")
            return False
        
        self.unity_map_corners[camera_id] = corners
        print(f"Camera {camera_id} Unity corners set:")
        for i, corner in enumerate(corners):
            print(f"  Corner {i+1}: ({corner['x']}, {corner['y']})")
        return True
    
    def set_unity_map_corners_from_coords(self, camera_id, x1, y1, x2, y2, x3, y3, x4, y4):
        """Unity ë§µì—ì„œ ê° ì¹´ë©”ë¼ ì˜ì—­ì˜ 4ê°œ ëª¨ì„œë¦¬ ì¢Œí‘œ ì„¤ì • (ê°œë³„ ì¢Œí‘œ ì…ë ¥)"""
        corners = [
            {"x": x1, "y": y1},  # ì™¼ìª½ ìƒë‹¨
            {"x": x2, "y": y2},  # ì˜¤ë¥¸ìª½ ìƒë‹¨
            {"x": x3, "y": y3},  # ì˜¤ë¥¸ìª½ í•˜ë‹¨
            {"x": x4, "y": y4}   # ì™¼ìª½ í•˜ë‹¨
        ]
        return self.set_unity_map_corners(camera_id, corners)
    
    def add_camera_calibration(self, camera_id, calibration_file):
        """ì¹´ë©”ë¼ë³„ ìº˜ë¦¬ë¸Œë ˆì´ì…˜ íŒŒì¼ ë¡œë“œ"""
        try:
            with open(calibration_file, 'r', encoding='utf-8') as f:
                data = json.load(f)
            
            self.homography_matrices[camera_id] = np.array(data['homography_matrix'])
            self.calibration_data[camera_id] = data
            
            print(f"Camera {camera_id} calibration loaded: {calibration_file}")
            return True
            
        except Exception as e:
            print(f"Failed to load calibration for camera {camera_id}: {e}")
            return False
    
    def transform_coordinates(self, camera_id, x, y):
        """ì¢Œí‘œ ë³€í™˜ (í˜¸ëª¨ê·¸ë˜í”¼ + Unity ë§µ 4ê°œ ì¢Œí‘œ ë³€í™˜)"""
        if camera_id not in self.homography_matrices:
            print(f"Warning: No homography matrix for camera {camera_id}")
            return x, y
        
        try:
            # 1ë‹¨ê³„: í˜¸ëª¨ê·¸ë˜í”¼ ë³€í™˜ (ì¹´ë©”ë¼ ì¢Œí‘œ â†’ ì‹¤ì œ ì§€ë©´ ì¢Œí‘œ)
            point = np.array([[x, y]], dtype=np.float32)
            transformed = cv2.perspectiveTransform(point, self.homography_matrices[camera_id])
            real_x, real_y = transformed[0][0], transformed[0][1]
            
            # 2ë‹¨ê³„: Unity ë§µ 4ê°œ ì¢Œí‘œë¡œ ë³€í™˜
            if camera_id in self.unity_map_corners:
                unity_corners = self.unity_map_corners[camera_id]
                
                # ì‹¤ì œ ì§€ë©´ ì¢Œí‘œë¥¼ 0~1 ë²”ìœ„ë¡œ ì •ê·œí™” (ìº˜ë¦¬ë¸Œë ˆì´ì…˜ ë°ì´í„° ê¸°ì¤€)
                if camera_id == 0:  # ì¹´ë©”ë¼ 0 (final01)
                    # 7.5m Ã— 7.8m ì˜ì—­ì„ 0~1ë¡œ ì •ê·œí™”
                    norm_x = max(0, min(1, real_x / 7.5))
                    norm_y = max(0, min(1, real_y / 7.8))
                elif camera_id == 1:  # ì¹´ë©”ë¼ 1 (final02)
                    # 9.0m Ã— 8.2m ì˜ì—­ì„ 0~1ë¡œ ì •ê·œí™”
                    norm_x = max(0, min(1, real_x / 9.0))
                    norm_y = max(0, min(1, real_y / 8.2))
                else:
                    # ê¸°ë³¸ê°’ (0~1 ë²”ìœ„ë¡œ ê°€ì •)
                    norm_x = max(0, min(1, real_x))
                    norm_y = max(0, min(1, real_y))
                
                # ì •ê·œí™”ëœ ì¢Œí‘œë¥¼ Unity ë§µì˜ 4ê°œ ëª¨ì„œë¦¬ ì¢Œí‘œë¡œ ë³€í™˜
                # 4ê°œ ëª¨ì„œë¦¬ ì¢Œí‘œë¥¼ ì‚¬ìš©í•œ ë°”ì´ë¦¬ë‹ˆì–´ ë³´ê°„
                unity_x = (unity_corners[0]["x"] * (1 - norm_x) * (1 - norm_y) +  # ì™¼ìª½ ìƒë‹¨
                          unity_corners[1]["x"] * norm_x * (1 - norm_y) +         # ì˜¤ë¥¸ìª½ ìƒë‹¨
                          unity_corners[2]["x"] * norm_x * norm_y +               # ì˜¤ë¥¸ìª½ í•˜ë‹¨
                          unity_corners[3]["x"] * (1 - norm_x) * norm_y)          # ì™¼ìª½ í•˜ë‹¨
                
                unity_y = (unity_corners[0]["y"] * (1 - norm_x) * (1 - norm_y) +  # ì™¼ìª½ ìƒë‹¨
                          unity_corners[1]["y"] * norm_x * (1 - norm_y) +         # ì˜¤ë¥¸ìª½ ìƒë‹¨
                          unity_corners[2]["y"] * norm_x * norm_y +               # ì˜¤ë¥¸ìª½ í•˜ë‹¨
                          unity_corners[3]["y"] * (1 - norm_x) * norm_y)          # ì™¼ìª½ í•˜ë‹¨
                
                print(f"[UNITY] Camera {camera_id}: Image({x:.1f}, {y:.1f}) -> Real({real_x:.3f}, {real_y:.3f}) -> Norm({norm_x:.3f}, {norm_y:.3f}) -> Unity({unity_x:.1f}, {unity_y:.1f})")
                return unity_x, unity_y
            else:
                print(f"Warning: No Unity corners for camera {camera_id}")
                return real_x, real_y
                
        except Exception as e:
            print(f"Coordinate transformation failed: {e}")
            return x, y
    
    def get_calibration_info(self, camera_id):
        """ìº˜ë¦¬ë¸Œë ˆì´ì…˜ ì •ë³´ ë°˜í™˜"""
        if camera_id in self.calibration_data:
            return self.calibration_data[camera_id]
        return None
    
    def get_unity_corners(self, camera_id):
        """Unity ë§µ 4ê°œ ëª¨ì„œë¦¬ ì¢Œí‘œ ë°˜í™˜"""
        return self.unity_map_corners.get(camera_id, None)
    
    def print_unity_corners(self, camera_id):
        """Unity ë§µ 4ê°œ ëª¨ì„œë¦¬ ì¢Œí‘œ ì¶œë ¥"""
        corners = self.get_unity_corners(camera_id)
        if corners:
            print(f"Camera {camera_id} Unity corners:")
            for i, corner in enumerate(corners):
                print(f"  Corner {i+1}: ({corner['x']}, {corner['y']})")
        else:
            print(f"No Unity corners set for camera {camera_id}")


class BackendClient:
    """ë°±ì—”ë“œ ì„œë²„ì™€ í†µì‹ í•˜ëŠ” í´ë¼ì´ì–¸íŠ¸"""
    
    def __init__(self, backend_url="http://localhost:5000"):
        self.backend_url = backend_url
        self.workers_endpoint = f"{backend_url}/workers"
    
    def send_worker_data(self, worker_data):
        """ì›Œì»¤ ë°ì´í„°ë¥¼ ë°±ì—”ë“œë¡œ ì „ì†¡"""
        try:
            response = requests.post(
                self.workers_endpoint,
                json=worker_data,
                headers={'Content-Type': 'application/json'},
                timeout=5
            )
            
            if response.status_code == 200:
                print(f"[BACKEND] Worker data sent successfully: {worker_data}")
                return True
            else:
                print(f"[BACKEND] Failed to send worker data. Status: {response.status_code}")
                return False
                
        except requests.exceptions.RequestException as e:
            print(f"[BACKEND] Error sending worker data: {e}")
            return False


class IntegratedTrackingSystem:
    """
    ReID ê¸°ëŠ¥ê³¼ í˜¸ëª¨ê·¸ë˜í”¼ ê¸°ëŠ¥ì„ í†µí•©í•œ ê°ì²´ ì¶”ì  ì‹œìŠ¤í…œ
    ë‘ ê°œì˜ ì˜ìƒì—ì„œ ê°ì²´ ì¶”ì ì´ ì˜ ë˜ë„ë¡ í˜¸ëª¨ê·¸ë˜í”¼ ì¢Œí‘œë¥¼ ì§ì ‘ ì…ë ¥í•˜ëŠ” ë°©ì‹
    """
    
    def __init__(self, video_paths=None, model_path=None, tracker_config=None, 
                 redis_conf=None, reid_conf=None, calibration_files=None, backend_url=None):
        # ì„¤ì • ë¡œë“œ
        self.model_path = model_path or settings.YOLO_MODEL_PATH
        self.tracker_config = tracker_config or settings.TRACKER_CONFIG
        redis_conf = redis_conf or settings.REDIS_CONFIG
        reid_conf = reid_conf or settings.REID_CONFIG
        
        # ë¹„ë””ì˜¤ ê²½ë¡œ ì„¤ì •
        self.video_paths = video_paths or settings.VIDEO_INPUT_PATHS
        
        # í˜¸ëª¨ê·¸ë˜í”¼ ë§¤ë‹ˆì € ì´ˆê¸°í™”
        self.homography_manager = HomographyManager()
        
        # ìº˜ë¦¬ë¸Œë ˆì´ì…˜ íŒŒì¼ ë¡œë“œ (ëª…ë ¹í–‰ ì¸ì ìš°ì„ , ì—†ìœ¼ë©´ settingsì—ì„œ ìë™ ë¡œë“œ)
        if calibration_files:
            for camera_id, calib_file in calibration_files.items():
                self.homography_manager.add_camera_calibration(camera_id, calib_file)
        else:
            # settings.pyì—ì„œ ìë™ìœ¼ë¡œ í˜¸ëª¨ê·¸ë˜í”¼ ë§¤íŠ¸ë¦­ìŠ¤ ë¡œë“œ
            for camera_id, matrix in settings.HOMOGRAPHY_MATRICES.items():
                self.homography_manager.homography_matrices[camera_id] = np.array(matrix)
                print(f"Camera {camera_id} homography matrix loaded from settings")
        
        # ë°±ì—”ë“œ í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
        self.backend_client = BackendClient(backend_url or "http://localhost:5000")
        
        # Redis í•¸ë“¤ëŸ¬ ì´ˆê¸°í™”
        redis_handler = FeatureStoreRedisHandler(
            redis_host=redis_conf.get("host", "localhost"),
            redis_port=redis_conf.get("port", 6379)
        )
        similarity = FeatureSimilarityCalculator()
        self.reid = GlobalReIDManager(redis_handler, similarity, similarity_threshold=reid_conf.get("threshold", 0.7))
        
        # ë¡œì»¬ IDì™€ ê¸€ë¡œë²Œ ID ë§¤í•‘ ì €ì¥ì†Œ
        self.local_to_global_mapping = {}
        
        # ImageProcessor ì´ˆê¸°í™”
        self.image_processor = ImageProcessor()
        
        # ìŠ¤ë ˆë“œë³„ ì„±ëŠ¥ ë¡œê±° ì €ì¥ì†Œ
        self.thread_performance_loggers = {}
        
        # ì¶”ì  ê²°ê³¼ ì €ì¥ì†Œ
        self.tracking_results = {}
        
        print("Integrated Tracking System initialized")
        print(f"Videos: {self.video_paths}")
        print(f"Model: {self.model_path}")
        print(f"Backend URL: {backend_url or 'http://localhost:5000'}")
        
        # ë¡œë“œëœ í˜¸ëª¨ê·¸ë˜í”¼ ë§¤íŠ¸ë¦­ìŠ¤ ì •ë³´ ì¶œë ¥
        print(f"Loaded homography matrices for cameras: {list(self.homography_manager.homography_matrices.keys())}")
        for camera_id in self.homography_manager.homography_matrices.keys():
            print(f"  Camera {camera_id}: Matrix shape {self.homography_manager.homography_matrices[camera_id].shape}")
    
    def create_detector_for_thread(self):
        """ìŠ¤ë ˆë“œë³„ ë…ë¦½ì ì¸ detector ìƒì„±"""
        return ByteTrackDetectorManager(self.model_path, self.tracker_config)
    
    def process_frame_with_reid_and_homography(self, frame, frame_id, camera_id, detector):
        """ReIDì™€ í˜¸ëª¨ê·¸ë˜í”¼ë¥¼ í†µí•©í•œ í”„ë ˆì„ ì²˜ë¦¬"""
        # ì„±ëŠ¥ ì¸¡ì • ì‹œì‘
        if camera_id not in self.thread_performance_loggers:
            self.thread_performance_loggers[camera_id] = PerformanceLogger(output_dir=f"result/camera_{camera_id}")
        
        logger = self.thread_performance_loggers[camera_id]
        logger.start_frame_timing(frame_id, camera_id)
        
        # ê¸€ë¡œë²Œ ReID ë§¤ë‹ˆì € í”„ë ˆì„ ì—…ë°ì´íŠ¸
        self.reid.update_frame(frame_id)
        
        # íƒì§€ ë° íŠ¸ë˜í‚¹
        logger.start_detection_timing()
        logger.start_tracking_timing()
        
        track_list = detector.detect_and_track(frame, frame_id)
        
        logger.end_detection_timing()
        logger.end_tracking_timing()
        
        # í”„ë ˆì„ë³„ ë§¤ì¹­ëœ íŠ¸ë™ ì¶”ì 
        frame_matched_tracks = set()
        frame_detections = []
        
        # ê°ì²´ ìˆ˜ ì„¤ì •
        logger.set_object_count(len(track_list))
        
        for track in track_list:
            local_id = track["track_id"]
            bbox = track["bbox"]
            
            # Feature ì¶”ì¶œ
            crop, feature = self.image_processor.process_track_for_reid(frame, track)
            
            # ReID ë§¤ì¹­
            camera_key = f"{camera_id}_{local_id}"
            if camera_key in self.local_to_global_mapping:
                # ê¸°ì¡´ ë§¤í•‘ ì‚¬ìš©
                global_id = self.local_to_global_mapping[camera_key]
                logger.start_same_camera_reid_timing()
                
                self.reid._update_track_camera(
                    global_id, feature, bbox, str(camera_id), frame_id, local_id
                )
                
                logger.end_same_camera_reid_timing()
            else:
                # ìƒˆë¡œìš´ ReID ë§¤ì¹­
                logger.start_cross_camera_reid_timing()
                
                global_id = self.reid.match_or_create(
                    features=feature,
                    bbox=bbox,
                    camera_id=str(camera_id),
                    frame_id=frame_id,
                    frame_shape=frame.shape[:2],
                    matched_tracks=frame_matched_tracks,
                    local_track_id=local_id
                )
                
                logger.end_cross_camera_reid_timing()
                
                if global_id is None:
                    global_id = local_id
                else:
                    self.local_to_global_mapping[camera_key] = global_id
            
            # ì¢Œí‘œ ë³€í™˜
            x1, y1, x2, y2, point_x, point_y = self.image_processor.get_bbox_coordinates(bbox)
            
            # í˜¸ëª¨ê·¸ë˜í”¼ ë³€í™˜
            real_x, real_y = self.homography_manager.transform_coordinates(camera_id, point_x, point_y)
            
            # ê²°ê³¼ ì €ì¥
            detection_data = {
                "camera_id": int(camera_id),
                "worker_id": int(global_id),
                "x": float(real_x),
                "y": float(real_y),
                "frame_id": int(frame_id),
                "local_id": int(local_id),
                "bbox": [int(x1), int(y1), int(x2), int(y2)],
                "image_coords": [float(point_x), float(point_y)]
            }
            frame_detections.append(detection_data)
            
            # ë°”ìš´ë”© ë°•ìŠ¤ ê·¸ë¦¬ê¸°
            cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 2)
            cv2.putText(frame, f'ID:{global_id}', (x1, y1 - 10), 
                       cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 255, 0), 2)
            
            # ì¢Œí‘œ ì •ë³´ í‘œì‹œ
            coord_text = f"({real_x:.1f}, {real_y:.1f})"
            cv2.putText(frame, coord_text, (x1, y2 + 15), 
                       cv2.FONT_HERSHEY_SIMPLEX, 0.4, (0, 0, 255), 1)
        
        # ì„±ëŠ¥ ë°ì´í„° ë¡œê¹…
        logger.log_frame_performance()
        
        return frame, frame_detections
    
    def send_detections_to_backend(self, detections):
        """ê°ì§€ ê²°ê³¼ë¥¼ ë°±ì—”ë“œë¡œ ì „ì†¡"""
        if not detections:
            return
        
        # ë°±ì—”ë“œ í˜•ì‹ì— ë§ê²Œ ë°ì´í„° ë³€í™˜
        worker_data = {
            "timestamp": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
            "workers": []
        }
        
        for det in detections:
            worker_info = {
                "worker_id": det.get("worker_id") or det.get("workerID"),
                "camera_id": det.get("camera_id") or det.get("cameraID"),
                "x": det.get("x") if det.get("x") is not None else det.get("position_X"),
                "y": det.get("y") if det.get("y") is not None else det.get("position_Y"),
                "frame_id": det.get("frame_id"),
                "local_id": det.get("local_id"),
            }
            worker_data["workers"].append(worker_info)
        
        # ë°±ì—”ë“œë¡œ ì „ì†¡
        self.backend_client.send_worker_data(worker_data)
    
    def run_video_thread(self, video_path, camera_id, frame_buffer, sync_event, stop_event):
        """ë¹„ë””ì˜¤ ì²˜ë¦¬ ìŠ¤ë ˆë“œ"""
        detector = self.create_detector_for_thread()
        
        cap = cv2.VideoCapture(video_path)
        frame_id = 0
        processed_frame_id = 0
        
        # í”„ë ˆì„ ìŠ¤í‚µ ì„¤ì •
        target_fps = 30
        frame_skip = 30/target_fps
        
        while cap.isOpened() and not stop_event.is_set():
            ret, frame = cap.read()
            if not ret:
                print(f"[{video_path}] Video ended")
                break
            
            frame_id += 1
            
            # í”„ë ˆì„ ìŠ¤í‚µ
            if frame_id % frame_skip != 0:
                continue
            
            processed_frame_id += 1
            
            # í”„ë ˆì„ ì²˜ë¦¬
            processed_frame, detections = self.process_frame_with_reid_and_homography(
                frame, processed_frame_id, camera_id, detector
            )
            
            # ë°±ì—”ë“œë¡œ ì „ì†¡
            self.send_detections_to_backend(detections)
            
            # ê²°ê³¼ ì €ì¥
            frame_data = {
                'video_path': video_path,
                'frame': processed_frame,
                'detections': detections,
                'frame_id': processed_frame_id
            }
            
            # ë²„í¼ì— ì €ì¥
            frame_buffer.put(frame_data)
            
            # ë™ê¸°í™” ëŒ€ê¸°
            sync_event.wait(0.1)
            sync_event.clear()
        
        cap.release()
        frame_buffer.put({'video_path': video_path, 'frame': None, 'detections': None, 'frame_id': -1})
    
    def run_multi_video_tracking(self):
        """ë©€í‹° ë¹„ë””ì˜¤ í†µí•© ì¶”ì  ì‹¤í–‰"""
        stop_event = threading.Event()
        sync_event = threading.Event()
        
        # ê° ë¹„ë””ì˜¤ë³„ í”„ë ˆì„ ë²„í¼
        frame_buffers = {video_path: queue.Queue(maxsize=1) for video_path in self.video_paths}
        
        # í”„ë ˆì„ ìˆ˜ì§‘ ìŠ¤ë ˆë“œ ìƒì„±
        collector_threads = []
        for i, video_path in enumerate(self.video_paths):
            thread = threading.Thread(
                target=self.run_video_thread,
                args=(video_path, i, frame_buffers[video_path], sync_event, stop_event),
                daemon=True
            )
            collector_threads.append(thread)
            thread.start()
        
        # GUI ì²˜ë¦¬
        active_videos = set(self.video_paths)
        latest_detections = {}
        
        # ê° ë¹„ë””ì˜¤ë³„ ì°½ ìƒì„±
        window_names = {}
        for i, video_path in enumerate(self.video_paths):
            window_name = f"Camera {i} - {Path(video_path).name}"
            window_names[video_path] = window_name
            cv2.namedWindow(window_name, cv2.WINDOW_NORMAL)
            cv2.resizeWindow(window_name, 800, 600)
        
        # ë™ê¸°í™”ëœ í”„ë ˆì„ ì²˜ë¦¬
        frame_count = 0
        max_frames = 3000
        
        while active_videos and frame_count < max_frames:
            # ëª¨ë“  ë¹„ë””ì˜¤ì—ì„œ í”„ë ˆì„ì´ ì¤€ë¹„ë  ë•Œê¹Œì§€ ëŒ€ê¸°
            all_frames_ready = True
            current_frames = {}
            
            for video_path in active_videos.copy():
                try:
                    frame_data = frame_buffers[video_path].get(timeout=0.01)
                    
                    if frame_data['frame'] is None:
                        active_videos.discard(video_path)
                        if video_path in latest_detections:
                            del latest_detections[video_path]
                        continue
                    
                    current_frames[video_path] = frame_data
                    
                except queue.Empty:
                    all_frames_ready = False
                    break
            
            if not all_frames_ready:
                time.sleep(0.01)
                continue
            
            # ëª¨ë“  í”„ë ˆì„ì´ ì¤€ë¹„ë˜ì—ˆìœ¼ë©´ ë™ì‹œì— ì²˜ë¦¬
            frame_count += 1
            print(f"[SYNC] Processing frame {frame_count} for all videos")
            
            # ëª¨ë“  ì¹´ë©”ë¼ì˜ ê°ì§€ ê²°ê³¼ ìˆ˜ì§‘
            all_detections = []
            
            for video_path, frame_data in current_frames.items():
                frame = frame_data['frame']
                detections = frame_data['detections']
                frame_id = frame_data['frame_id']
                
                if detections:
                    latest_detections[video_path] = detections
                    all_detections.extend(detections)
                
                # ê° ë¹„ë””ì˜¤ë¥¼ ë³„ë„ì˜ ì°½ì— í‘œì‹œ
                if frame is not None:
                    window_name = window_names[video_path]
                    cv2.imshow(window_name, frame)
            
            # í‚¤ ì…ë ¥ ì²˜ë¦¬
            key = cv2.waitKey(1) & 0xFF
            if key == ord('q'):
                break
            
            # ëª¨ë“  ìŠ¤ë ˆë“œì—ê²Œ ë‹¤ìŒ í”„ë ˆì„ ì²˜ë¦¬ í—ˆê°€ ì‹ í˜¸ ì „ì†¡
            sync_event.set()
        
        # ìŠ¤ë ˆë“œ ì •ë¦¬
        stop_event.set()
        for thread in collector_threads:
            thread.join(timeout=1.0)
        
        # ëª¨ë“  ì°½ ë‹«ê¸°
        for window_name in window_names.values():
            cv2.destroyWindow(window_name)
        
        return all_detections
    
    def save_tracking_results(self, output_file="tracking_results.json"):
        """ì¶”ì  ê²°ê³¼ ì €ì¥"""
        results = {
            "timestamp": time.strftime("%Y-%m-%d %H:%M:%S"),
            "videos": self.video_paths,
            "model": self.model_path,
            "total_detections": len(self.tracking_results),
            "results": self.tracking_results
        }
        
        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(results, f, indent=2, ensure_ascii=False)
        
        print(f"Tracking results saved to: {output_file}")


def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    parser = argparse.ArgumentParser(
        description="Integrated ReID and Homography Tracking System"
    )
    parser.add_argument(
        '--videos',
        nargs='+',
        type=str,
        default=settings.VIDEO_INPUT_PATHS,
        help='List of video file paths.'
    )
    parser.add_argument(
        '--yolo_model',
        type=str,
        default="models/weights/bestcctv.pt",
        help='Path to the YOLOv8 model file.'
    )
    parser.add_argument(
        '--calibration_files',
        nargs='+',
        type=str,
        help='List of calibration files for each camera (in order).'
    )
    parser.add_argument(
        '--redis_host',
        type=str,
        default="localhost",
        help='Redis server host.'
    )
    parser.add_argument(
        '--redis_port',
        type=int,
        default=6379,
        help='Redis server port.'
    )
    parser.add_argument(
        '--backend_url',
        type=str,
        default="http://localhost:5000",
        help='Backend server URL.'
    )
    parser.add_argument(
        '--unity_corners',
        nargs='+',
        type=str,
        help='Unity map corners for each camera in format "camera_id:x1,y1,x2,y2,x3,y3,x4,y4" (clockwise from top-left)'
    )
    args = parser.parse_args()
    
    # ìº˜ë¦¬ë¸Œë ˆì´ì…˜ íŒŒì¼ ë§¤í•‘
    calibration_files = {}
    if args.calibration_files:
        for i, calib_file in enumerate(args.calibration_files):
            calibration_files[i] = calib_file
    else:
        # ìº˜ë¦¬ë¸Œë ˆì´ì…˜ íŒŒì¼ì´ ì§€ì •ë˜ì§€ ì•Šìœ¼ë©´ settingsì—ì„œ ìë™ ë¡œë“œ
        print("No calibration files specified. Using homography matrices from settings.py")
    
    # ì‹œìŠ¤í…œ ì´ˆê¸°í™”
    tracker_config = settings.TRACKER_CONFIG
    reid_config = settings.REID_CONFIG
    
    redis_conf = {
        "host": args.redis_host,
        "port": args.redis_port,
        "camera_id": "camera_0"
    }
    
    # í†µí•© ì¶”ì  ì‹œìŠ¤í…œ ìƒì„±
    tracking_system = IntegratedTrackingSystem(
        video_paths=args.videos,
        model_path=args.yolo_model,
        tracker_config=tracker_config,
        redis_conf=redis_conf,
        reid_conf=reid_config,
        calibration_files=calibration_files,
        backend_url=args.backend_url
    )
    
    # Unity ì¢Œí‘œ ì„¤ì •
    if args.unity_corners:
        for corner_str in args.unity_corners:
            try:
                # í˜•ì‹: "camera_id:x1,y1,x2,y2,x3,y3,x4,y4"
                camera_part, coords_part = corner_str.split(':', 1)
                camera_id = int(camera_part)
                coords = [float(x) for x in coords_part.split(',')]
                
                if len(coords) == 8:
                    tracking_system.homography_manager.set_unity_map_corners_from_coords(
                        camera_id, coords[0], coords[1], coords[2], coords[3], 
                        coords[4], coords[5], coords[6], coords[7]
                    )
                else:
                    print(f"Error: Need exactly 8 coordinates for camera {camera_id}")
            except Exception as e:
                print(f"Error parsing Unity corners: {corner_str}, Error: {e}")
    
    # Unity ì¢Œí‘œ ì„¤ì • (ì˜ˆì‹œ - ì‹¤ì œ ê°’ìœ¼ë¡œ ìˆ˜ì • í•„ìš”)
    # ë³µë„ì™€ ë°©ì˜ Unity ì¢Œí‘œë¥¼ ì—¬ê¸°ì„œ ì„¤ì •í•˜ê±°ë‚˜ ëª…ë ¹í–‰ ì¸ìë¡œ ì „ë‹¬
    # tracking_system.homography_manager.set_unity_map_corners_from_coords(
    #     0,  # ì¹´ë©”ë¼ 0 (ë³µë„)
    #     0, 0,    # ì™¼ìª½ ìƒë‹¨
    #     100, 0,  # ì˜¤ë¥¸ìª½ ìƒë‹¨
    #     100, 50, # ì˜¤ë¥¸ìª½ í•˜ë‹¨
    #     0, 50    # ì™¼ìª½ í•˜ë‹¨
    # )
    # tracking_system.homography_manager.set_unity_map_corners_from_coords(
    #     1,  # ì¹´ë©”ë¼ 1 (ë°©)
    #     100, 0,   # ì™¼ìª½ ìƒë‹¨
    #     200, 0,   # ì˜¤ë¥¸ìª½ ìƒë‹¨
    #     200, 100, # ì˜¤ë¥¸ìª½ í•˜ë‹¨
    #     100, 100  # ì™¼ìª½ í•˜ë‹¨
    # )
    
    print(f"â–¶ Processing {len(args.videos)} videos with integrated tracking")
    for i, video_path in enumerate(args.videos):
        print(f"  Camera {i}: {video_path}")
        if i in calibration_files:
            print(f"    Calibration: {calibration_files[i]}")
        else:
            print(f"    Homography: Loaded from settings.py")
        tracking_system.homography_manager.print_unity_corners(i)
    
    # ë©€í‹° ë¹„ë””ì˜¤ ì¶”ì  ì‹¤í–‰
    all_detections = tracking_system.run_multi_video_tracking()
    print(f"â–¶ Total detections: {len(all_detections)}")
    
    # ì„±ëŠ¥ ìš”ì•½ ì¶œë ¥
    print("\n" + "="*60)
    print("ğŸ“Š INTEGRATED TRACKING PERFORMANCE SUMMARY")
    print("="*60)
    
    for camera_id, thread_logger in tracking_system.thread_performance_loggers.items():
        print(f"\nğŸ“Š Camera {camera_id} Performance Summary:")
        thread_logger.print_summary()
    
    print("="*60)
    
    # ê²°ê³¼ ì €ì¥
    tracking_system.save_tracking_results()


if __name__ == '__main__':
    main()
