import cv2
import numpy as np
from pathlib import Path
import sys
import torch
from scipy.spatial.distance import cdist
import threading
import queue
import argparse
import time
from performance_logger import PerformanceLogger

PROJECT_ROOT = Path(__file__).resolve().parent.parent
EXTRA_PATHS = [
    str(PROJECT_ROOT),                      # ë£¨íŠ¸ ìì²´ (app, ByteTrack, frontend ë“± import ê°€ëŠ¥)
    str(PROJECT_ROOT / "ByteTrack"),        # ByteTrack ì§ì ‘ ì°¸ì¡°ê°€ í•„ìš”í•œ ê²½ìš°
    str(PROJECT_ROOT / "deep-person-reid-master"),  # í•„ìš”í•œ ê²½ìš°ë§Œ
    str(PROJECT_ROOT / "app" / "models" / "mapping"),   # point_transformer ê²½ë¡œ ìˆ˜ì •
]

for p in EXTRA_PATHS:
    if p not in sys.path:
        sys.path.insert(0, p)

# np.float í˜¸í™˜ì„± ë¬¸ì œ í•´ê²°
if not hasattr(np, 'float'):
    np.float = float

from detector.detector_manager import ByteTrackDetectorManager
from reid.reid_manager import GlobalReIDManager
from reid.redis_handler import FeatureStoreRedisHandler
from reid.similarity import FeatureSimilarityCalculator
from config import settings
from models.mapping.point_transformer import transform_point
from image_processor import ImageProcessor


class AppOrchestrator:
    """
    ì „ì²´ ê°ì²´ íƒì§€, ì¶”ì , ReID ì¬ë¶€ì—¬ íë¦„ì„ í†µí•© ì‹¤í–‰í•˜ëŠ” ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´í„°
    ë©€í‹°ìŠ¤ë ˆë”© ì§€ì›ìœ¼ë¡œ ì—¬ëŸ¬ ë¹„ë””ì˜¤ë¥¼ ë™ì‹œì— ì²˜ë¦¬
    """

    def __init__(self, model_path: str, tracker_config: dict, redis_conf: dict, reid_conf: dict):
        # ê³µìœ  ì»´í¬ë„ŒíŠ¸ë“¤
        self.model_path = model_path
        self.tracker_config = tracker_config
        self.redis_conf = redis_conf
        self.reid_conf = reid_conf
        
        # ë¡œì»¬ IDì™€ ê¸€ë¡œë²Œ ID ë§¤í•‘ ì €ì¥ì†Œ
        self.local_to_global_mapping = {}
        
        # ImageProcessor ì´ˆê¸°í™” (feature ì¶”ì¶œ ì±…ì„ ë¶„ë¦¬)
        self.image_processor = ImageProcessor()

        # Redis ë° ReID ë§¤ë‹ˆì € ì´ˆê¸°í™” (ê³µìœ )
        redis_handler = FeatureStoreRedisHandler(
            redis_host=redis_conf.get("host", "localhost"),
            redis_port=redis_conf.get("port", 6379),
            feature_ttl=reid_conf.get("ttl", 300)
        )
        similarity = FeatureSimilarityCalculator()
        self.reid = GlobalReIDManager(redis_handler, similarity, similarity_threshold=reid_conf.get("threshold", 0.7))

        self.camera_id = redis_conf.get("camera_id", "cam01")
        
        # ìŠ¤ë ˆë“œë³„ ì„±ëŠ¥ ë¡œê±° ì €ì¥ì†Œ
        self.thread_performance_loggers = {}

    def create_detector_for_thread(self):
        """ìŠ¤ë ˆë“œë³„ ë…ë¦½ì ì¸ detector ìƒì„±"""
        return ByteTrackDetectorManager(self.model_path, self.tracker_config)

    def run_video(self, video_path):
        """ë‹¨ì¼ ë¹„ë””ì˜¤ ì²˜ë¦¬ (ê¸°ì¡´ ë©”ì„œë“œ)"""
        detector = self.create_detector_for_thread()
        
        # ë‹¨ì¼ ë¹„ë””ì˜¤ìš© ì„±ëŠ¥ ë¡œê±° ìƒì„±
        video_logger = PerformanceLogger(output_dir="result/single_video")
        self.thread_performance_loggers[0] = video_logger
        
        cap = cv2.VideoCapture(video_path)
        frame_id = 0

        while cap.isOpened():
            ret, frame = cap.read()
            if not ret:
                break

            frame_id += 1
            
            # ì„±ëŠ¥ ì¸¡ì • ì‹œì‘
            video_logger.start_frame_timing(frame_id, 0)  # ë‹¨ì¼ ë¹„ë””ì˜¤ëŠ” ì¹´ë©”ë¼ ID 0
            
            # ê¸€ë¡œë²Œ ReID ë§¤ë‹ˆì € í”„ë ˆì„ ì—…ë°ì´íŠ¸
            self.reid.update_frame(frame_id)
            
            # íƒì§€ ë° íŠ¸ë˜í‚¹ íƒ€ì´ë° ì‹œì‘
            video_logger.start_detection_timing()
            video_logger.start_tracking_timing()
            
            # ì›ë³¸ì˜ ë³µì¡í•œ íƒì§€ ë¡œì§ ì‚¬ìš©
            track_list = detector.detect_and_track(frame, frame_id)
            
            # íƒì§€ ë° íŠ¸ë˜í‚¹ íƒ€ì´ë° ì¢…ë£Œ
            video_logger.end_detection_timing()
            video_logger.end_tracking_timing()

            # í”„ë ˆì„ë³„ ë§¤ì¹­ëœ íŠ¸ë™ ì¶”ì 
            frame_matched_tracks = set()
            
            # ê°ì²´ ìˆ˜ ì„¤ì •
            video_logger.set_object_count(len(track_list))

            for track in track_list:
                local_id = track["track_id"]
                bbox = track["bbox"]

                # --- Feature ì¶”ì¶œ ë¡œì§ (ImageProcessor ì‚¬ìš©) ---
                crop, feature = self.image_processor.process_track_for_reid(frame, track)

                # ë¡œì»¬ IDì™€ ê¸€ë¡œë²Œ ID ë§¤í•‘ í™•ì¸
                camera_key = f"{self.camera_id}_{local_id}"
                if camera_key in self.local_to_global_mapping:
                    # ê¸°ì¡´ ë§¤í•‘ì´ ìˆìœ¼ë©´ ì‚¬ìš© (ê°™ì€ ì¹´ë©”ë¼ ë‚´ ReID)
                    global_id = self.local_to_global_mapping[camera_key]
                    print(f"[DEBUG] Using existing mapping: Local {local_id} -> Global {global_id}")
                    
                    # ê°™ì€ ì¹´ë©”ë¼ ë‚´ ReID íƒ€ì´ë° ì‹œì‘
                    video_logger.start_same_camera_reid_timing()
                    
                    # ReID ë§¤ë‹ˆì €ë¥¼ í†µí•´ ì—…ë°ì´íŠ¸ (Redis ìƒíƒœ ì¼ê´€ì„± ìœ ì§€)
                    self.reid._update_track_camera(
                        global_id, feature, bbox, self.camera_id, frame_id, local_id
                    )
                    
                    # ê°™ì€ ì¹´ë©”ë¼ ë‚´ ReID íƒ€ì´ë° ì¢…ë£Œ
                    video_logger.end_same_camera_reid_timing()
                else:
                    # ìƒˆë¡œìš´ ReID ë§¤ì¹­ ì‹œë„ (ë‹¤ë¥¸ ì¹´ë©”ë¼ ê°„ ReID)
                    video_logger.start_cross_camera_reid_timing()
                    
                    global_id = self.reid.match_or_create(
                        features=feature,
                        bbox=bbox,
                        camera_id=self.camera_id,
                        frame_id=frame_id,
                        frame_shape=frame.shape[:2],
                        matched_tracks=frame_matched_tracks,  # í”„ë ˆì„ ë‚´ì—ì„œ ê³µìœ 
                        local_track_id=local_id
                    )
                    
                    # ë‹¤ë¥¸ ì¹´ë©”ë¼ ê°„ ReID íƒ€ì´ë° ì¢…ë£Œ
                    video_logger.end_cross_camera_reid_timing()
                    
                    if global_id is None:
                        global_id = local_id  # ë§¤ì¹­ ì‹¤íŒ¨ ì‹œ ë¡œì»¬ ID ì‚¬ìš©
                    else:
                        # ìƒˆë¡œìš´ ë§¤í•‘ ì €ì¥
                        self.local_to_global_mapping[camera_key] = global_id
                        print(f"[DEBUG] New mapping: Local {local_id} -> Global {global_id}")

                # --- ì¢Œí‘œ ë³€í™˜ (ImageProcessor ì‚¬ìš©) ---
                x1, y1, x2, y2, point_x, point_y = self.image_processor.get_bbox_coordinates(bbox)
                
                try:
                    # ì‹¤ì œ ì¢Œí‘œë¡œ ë³€í™˜ (ì„¤ì •ì—ì„œ ê°€ì ¸ì˜¨ ë§¤íŠ¸ë¦­ìŠ¤ ì‚¬ìš©)
                    real_x, real_y = point_x, point_y #í…ŒìŠ¤íŠ¸ì‹œ ì—°ì‚° ìµœì†Œí™” ìœ„í•œ ì˜µì…˜
                    # real_x, real_y = transform_point(point_x, point_y, settings.HOMOGRAPHY_MATRIX)
                    
                    print(f"[DEBUG] Camera {self.camera_id}, Worker {global_id}: Image({point_x:.1f}, {point_y:.1f}) -> Real({real_x:.4f}, {real_y:.4f})")
                except Exception as e:
                    print(f"Warning: Coordinate transformation failed: {e}")
                    real_x, real_y = point_x, point_y

                # --- ê²°ê³¼ ë””ìŠ¤í”Œë ˆì´ ---
                cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 2)
                cv2.putText(frame, f"ID: {global_id}", (x1, y1 - 10),
                            cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 0), 2)

            # ì„±ëŠ¥ ë°ì´í„° ë¡œê¹…
            video_logger.log_frame_performance()

            cv2.imshow("Tracking", frame)
            if cv2.waitKey(1) & 0xFF == ord('q'):
                break

        cap.release()
        cv2.destroyAllWindows()

    def run_video_thread(self, video_path, camera_id, frame_buffer, sync_event, stop_event):
        """í”„ë ˆì„ ìˆ˜ì§‘ ì „ìš© ìŠ¤ë ˆë“œ (ë™ê¸°í™”ë¨)"""
        detector = self.create_detector_for_thread()
        
        # ìŠ¤ë ˆë“œë³„ ë…ë¦½ì ì¸ ì„±ëŠ¥ ë¡œê±° ìƒì„±
        thread_logger = PerformanceLogger(output_dir=f"result/camera_{camera_id}")
        self.thread_performance_loggers[camera_id] = thread_logger
        
        cap = cv2.VideoCapture(video_path)
        frame_id = 0  # ì›ë³¸ ë¹„ë””ì˜¤ì˜ ì‹¤ì œ í”„ë ˆì„ ë²ˆí˜¸
        processed_frame_id = 0  # ì‹¤ì œ ì²˜ë¦¬ëœ í”„ë ˆì„ì˜ ìˆœì°¨ì  ë²ˆí˜¸

        # í”„ë ˆì„ ìŠ¤í‚µ ì„¤ì •
        target_fps = 30  # ëª©í‘œ FPS
        frame_skip = 30/target_fps # ìŠ¤í‚µí•  í”„ë ˆì„ ìˆ˜
        
        while cap.isOpened() and not stop_event.is_set():
            ret, frame = cap.read()
            if not ret:
                print(f"[{video_path}] Video ended")
                break

            frame_id += 1  # ì›ë³¸ í”„ë ˆì„ ë²ˆí˜¸ ì¦ê°€

            # í”„ë ˆì„ ìŠ¤í‚µ: frame_skip í”„ë ˆì„ë§ˆë‹¤ í•˜ë‚˜ì”©ë§Œ ì²˜ë¦¬
            if frame_id % frame_skip != 0:
                print(f"[DEBUG] Skipping frame {frame_id}")
                continue  # ì´ í”„ë ˆì„ì€ ìŠ¤í‚µ
            
            processed_frame_id += 1  # ì²˜ë¦¬ëœ í”„ë ˆì„ ë²ˆí˜¸ ì¦ê°€
            print(f"[DEBUG] Processing frame {frame_id} -> processed_frame_id {processed_frame_id}")
            
            # ì„±ëŠ¥ ì¸¡ì • ì‹œì‘
            thread_logger.start_frame_timing(processed_frame_id, camera_id)
            
            # ê¸€ë¡œë²Œ ReID ë§¤ë‹ˆì € í”„ë ˆì„ ì—…ë°ì´íŠ¸ (processed_frame_id ì‚¬ìš©)
            self.reid.update_frame(processed_frame_id)
            
            # íƒì§€ ë° íŠ¸ë˜í‚¹ íƒ€ì´ë° ì‹œì‘
            thread_logger.start_detection_timing()
            thread_logger.start_tracking_timing()
            
            # ì›ë³¸ì˜ ë³µì¡í•œ íƒì§€ ë¡œì§ ì‚¬ìš© (processed_frame_id ì‚¬ìš©)
            track_list = detector.detect_and_track(frame, processed_frame_id)
            
            # íƒì§€ ë° íŠ¸ë˜í‚¹ íƒ€ì´ë° ì¢…ë£Œ
            thread_logger.end_detection_timing()
            thread_logger.end_tracking_timing()

            # í”„ë ˆì„ë³„ ë§¤ì¹­ëœ íŠ¸ë™ ì¶”ì 
            frame_matched_tracks = set()
            
            frame_detections_json = []
            
            # ê°ì²´ ìˆ˜ ì„¤ì •
            thread_logger.set_object_count(len(track_list))
            
            for track in track_list:
                local_id = track["track_id"]
                bbox = track["bbox"]

                # --- Feature ì¶”ì¶œ ë¡œì§ (ImageProcessor ì‚¬ìš©) ---
                crop, feature = self.image_processor.process_track_for_reid(frame, track)

                # ë¡œì»¬ IDì™€ ê¸€ë¡œë²Œ ID ë§¤í•‘ í™•ì¸
                camera_key = f"{camera_id}_{local_id}"
                if camera_key in self.local_to_global_mapping:
                    # ê¸°ì¡´ ë§¤í•‘ì´ ìˆìœ¼ë©´ ì‚¬ìš© (ê°™ì€ ì¹´ë©”ë¼ ë‚´ ReID)
                    global_id = self.local_to_global_mapping[camera_key]
                    
                    print(f"[DEBUG] Using existing mapping: Local {local_id} -> Global {global_id}")
                    
                    # ê°™ì€ ì¹´ë©”ë¼ ë‚´ ReID íƒ€ì´ë° ì‹œì‘
                    thread_logger.start_same_camera_reid_timing()
                    
                    # ReID ë§¤ë‹ˆì €ë¥¼ í†µí•´ ì—…ë°ì´íŠ¸ (frame_id ì‚¬ìš© - ì›ë³¸ í”„ë ˆì„ ë²ˆí˜¸)
                    self.reid._update_track_camera(
                        global_id, feature, bbox, str(camera_id), frame_id, local_id
                    )
                    
                    # ê°™ì€ ì¹´ë©”ë¼ ë‚´ ReID íƒ€ì´ë° ì¢…ë£Œ
                    thread_logger.end_same_camera_reid_timing()
                else:
                    # ìƒˆë¡œìš´ ReID ë§¤ì¹­ ì‹œë„ (ë‹¤ë¥¸ ì¹´ë©”ë¼ ê°„ ReID)
                    thread_logger.start_cross_camera_reid_timing()
                    
                    global_id = self.reid.match_or_create(
                        features=feature,
                        bbox=bbox,
                        camera_id=str(camera_id),
                        frame_id=frame_id,  # ì›ë³¸ í”„ë ˆì„ ë²ˆí˜¸
                        frame_shape=frame.shape[:2],
                        matched_tracks=frame_matched_tracks,
                        local_track_id=local_id
                    )
                    
                    # ë‹¤ë¥¸ ì¹´ë©”ë¼ ê°„ ReID íƒ€ì´ë° ì¢…ë£Œ
                    thread_logger.end_cross_camera_reid_timing()
                    
                    if global_id is None:
                        global_id = local_id
                    else:
                        # ìƒˆë¡œìš´ ë§¤í•‘ ì €ì¥ reid ë§¤ì¹­ì— ì„±ê³µ
                        self.local_to_global_mapping[camera_key] = global_id
                        print(f"[DEBUG] New mapping: Local {local_id} -> Global {global_id}")

                # --- ì¢Œí‘œ ë³€í™˜ ---
                x1, y1, x2, y2, point_x, point_y = self.image_processor.get_bbox_coordinates(bbox)
                
                try:
                    real_x, real_y = transform_point(point_x, point_y, settings.HOMOGRAPHY_MATRIX)
                    print(f"[DEBUG] Camera {camera_id}, Worker {global_id}: Image({point_x:.1f}, {point_y:.1f}) -> Real({real_x:.4f}, {real_y:.4f})")
                except Exception as e:
                    print(f"Warning: Coordinate transformation failed: {e}")
                    real_x, real_y = point_x, point_y

                # JSON ë°ì´í„° ìƒì„± (processed_frame_id ì‚¬ìš© - ì²˜ë¦¬ëœ í”„ë ˆì„ ë²ˆí˜¸)
                detection_data = {
                    "cameraID": int(camera_id),
                    "workerID": int(global_id),
                    "position_X": real_x,
                    "position_Y": real_y,
                    "frame_id": processed_frame_id  # ì²˜ë¦¬ëœ í”„ë ˆì„ ë²ˆí˜¸
                }
                frame_detections_json.append(detection_data)

                # ë°”ìš´ë”© ë°•ìŠ¤ ê·¸ë¦¬ê¸°
                cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 2)
                cv2.putText(frame, f'ID:{global_id}', (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 255, 0), 2)

            # ì„±ëŠ¥ ë°ì´í„° ë¡œê¹…
            thread_logger.log_frame_performance()
            
            # í”„ë ˆì„ ë°ì´í„°ë¥¼ ë²„í¼ì— ì €ì¥ (processed_frame_id ì‚¬ìš©)
            frame_data = {
                'video_path': video_path,
                'frame': frame,
                'detections': frame_detections_json,
                'frame_id': processed_frame_id  # ì²˜ë¦¬ëœ í”„ë ˆì„ ë²ˆí˜¸
            }
            
            # ë™ê¸°í™”: ë©”ì¸ ìŠ¤ë ˆë“œê°€ ì²˜ë¦¬í•  ì¤€ë¹„ê°€ ë  ë•Œê¹Œì§€ ëŒ€ê¸°
            frame_buffer.put(frame_data)
            
            # ë©”ì¸ ìŠ¤ë ˆë“œì˜ ì²˜ë¦¬ ì™„ë£Œ ì‹ í˜¸ ëŒ€ê¸°
            sync_event.wait(0.1)
            sync_event.clear()  # ì´ë²¤íŠ¸ ë¦¬ì…‹

        cap.release()
        # ì¢…ë£Œ ì‹ í˜¸ ì „ì†¡
        frame_buffer.put({'video_path': video_path, 'frame': None, 'detections': None, 'frame_id': -1}) 

    def run_multi_video(self, video_paths):
        """ë™ê¸°í™”ëœ ë©€í‹° ë¹„ë””ì˜¤ ì²˜ë¦¬"""
        stop_event = threading.Event()
        sync_event = threading.Event()  # ë™ê¸°í™” ì´ë²¤íŠ¸
        
        # ê° ë¹„ë””ì˜¤ë³„ í”„ë ˆì„ ë²„í¼
        frame_buffers = {video_path: queue.Queue(maxsize=1) for video_path in video_paths}
        
        # í”„ë ˆì„ ìˆ˜ì§‘ ìŠ¤ë ˆë“œ ìƒì„±
        collector_threads = []
        for i, video_path in enumerate(video_paths):
            thread = threading.Thread(
                target=self.run_video_thread,
                args=(video_path, i, frame_buffers[video_path], sync_event, stop_event),
                daemon=True
            )
            collector_threads.append(thread)
            thread.start()

        # GUI ì²˜ë¦¬
        latest_frames = {}
        active_videos = set(video_paths)
        latest_detections = {}
        
        # ê° ë¹„ë””ì˜¤ë³„ ì°½ ìƒì„±
        window_names = {}
        for i, video_path in enumerate(video_paths):
            window_name = f"Camera {i} - {Path(video_path).name}"
            window_names[video_path] = window_name
            cv2.namedWindow(window_name, cv2.WINDOW_NORMAL)
            cv2.resizeWindow(window_name, settings.GUI_CONFIG["window_width"], settings.GUI_CONFIG["window_height"])
        
        # ë™ê¸°í™”ëœ í”„ë ˆì„ ì²˜ë¦¬
        frame_count = 0
        max_frames = settings.MULTITHREADING_CONFIG["max_frames"]
        
        while active_videos and frame_count < max_frames:
            # ëª¨ë“  ë¹„ë””ì˜¤ì—ì„œ í”„ë ˆì„ì´ ì¤€ë¹„ë  ë•Œê¹Œì§€ ëŒ€ê¸°
            all_frames_ready = True
            current_frames = {}
            
            for video_path in active_videos.copy():
                try:
                    frame_data = frame_buffers[video_path].get(timeout=0.01)  # 10ms íƒ€ì„ì•„ì›ƒ
                    
                    if frame_data['frame'] is None:
                        # ë¹„ë””ì˜¤ ì¢…ë£Œ ì‹ í˜¸
                        active_videos.discard(video_path)
                        if video_path in latest_detections:
                            del latest_detections[video_path]
                        continue
                    
                    current_frames[video_path] = frame_data
                    
                except queue.Empty:
                    # í”„ë ˆì„ì´ ì•„ì§ ì¤€ë¹„ë˜ì§€ ì•ŠìŒ
                    all_frames_ready = False
                    break
            
            # ëª¨ë“  í”„ë ˆì„ì´ ì¤€ë¹„ë˜ì§€ ì•Šì•˜ìœ¼ë©´ ì ì‹œ ëŒ€ê¸°
            if not all_frames_ready:
                time.sleep(0.01)  # 10ms ëŒ€ê¸°
                continue
            
            # ëª¨ë“  í”„ë ˆì„ì´ ì¤€ë¹„ë˜ì—ˆìœ¼ë©´ ë™ì‹œì— ì²˜ë¦¬
            frame_count += 1
            print(f"[SYNC] Processing frame {frame_count} for all videos")
            
            for video_path, frame_data in current_frames.items():
                frame = frame_data['frame']
                detections = frame_data['detections']
                frame_id = frame_data['frame_id']
                
                if detections:
                    latest_detections[video_path] = detections

                # ê° ë¹„ë””ì˜¤ë¥¼ ë³„ë„ì˜ ì°½ì— í‘œì‹œ
                if frame is not None:
                    window_name = window_names[video_path]
                    cv2.imshow(window_name, frame)
            
            # ëª¨ë“  ì°½ì—ì„œ 'q' í‚¤ë¥¼ ëˆ„ë¥´ë©´ ì¢…ë£Œ
            key = cv2.waitKey(1) & 0xFF
            if key == ord('q'):
                break
            
            # ëª¨ë“  ìŠ¤ë ˆë“œì—ê²Œ ë‹¤ìŒ í”„ë ˆì„ ì²˜ë¦¬ í—ˆê°€ ì‹ í˜¸ ì „ì†¡
            sync_event.set()
        
        # ëª¨ë“  ì¹´ë©”ë¼ì˜ ê°ì§€ ê²°ê³¼ë¥¼ í•©ì³ì„œ ë°˜í™˜
        all_detections = []
        for detections in latest_detections.values():
            all_detections.extend(detections)
        
        # ìŠ¤ë ˆë“œ ì •ë¦¬
        stop_event.set()
        for thread in collector_threads:
            thread.join(timeout=settings.MULTITHREADING_CONFIG["thread_timeout"])
        
        # ëª¨ë“  ì°½ ë‹«ê¸°
        for window_name in window_names.values():
            cv2.destroyWindow(window_name)
        
        return all_detections




def main():
    """ë©”ì¸ í•¨ìˆ˜: ë©€í‹°ìŠ¤ë ˆë”© ì§€ì›"""
    import argparse
    from config import settings

    parser = argparse.ArgumentParser(
        description="YOLOv8 with ByteTrack and Redis Global Re-ID V2 for Multi-Video Tracking"
    )
    parser.add_argument(
        '--videos',
        nargs='+',
        type=str,
        default=settings.VIDEO_INPUT_PATHS,
        help='List of video file paths.'
    )
    parser.add_argument(
        '--yolo_model',
        type=str,
        default="models/weights/bestcctv.pt",
        help='Path to the YOLOv8 model file.'
    )
    parser.add_argument(
        '--redis_host',
        type=str,
        default="localhost",
        help='Redis server host.'
    )
    parser.add_argument(
        '--redis_port',
        type=int,
        default=6379,
        help='Redis server port.'
    )
    parser.add_argument(
        '--multi_thread',
        action='store_true',
        help='Enable multi-threading for multiple videos'
    )
    args = parser.parse_args()

    tracker_config = settings.TRACKER_CONFIG
    reid_config = settings.REID_CONFIG

    redis_conf = {
        "host": args.redis_host,
        "port": args.redis_port,
        "camera_id": "cam01"
    }

    app = AppOrchestrator(
        model_path=args.yolo_model,
        tracker_config=tracker_config,
        redis_conf=redis_conf,
        reid_conf=reid_config
    )

    if args.multi_thread and len(args.videos) > 1:
        print(f"â–¶ Processing {len(args.videos)} videos with multi-threading")
        for video_path in args.videos:
            print(f"  - {video_path}")
        
        # ë©€í‹°ìŠ¤ë ˆë”©ìœ¼ë¡œ ì—¬ëŸ¬ ë¹„ë””ì˜¤ ì²˜ë¦¬
        all_detections = app.run_multi_video(args.videos)
        print(f"â–¶ Total detections: {len(all_detections)}")
        
        # ì„±ëŠ¥ ìš”ì•½ ì¶œë ¥ (ëª¨ë“  ìŠ¤ë ˆë“œ ë¡œê±° í•©ì³ì„œ)
        print("\n" + "="*60)
        print("ğŸ“Š COMBINED PERFORMANCE SUMMARY")
        print("="*60)
        
        # ê° ìŠ¤ë ˆë“œë³„ ë¡œê±° ìš”ì•½
        for camera_id, thread_logger in app.thread_performance_loggers.items():
            print(f"\nğŸ“Š Camera {camera_id} Performance Summary:")
            thread_logger.print_summary()
        
        print("="*60)
    else:
        # ë‹¨ì¼ ë¹„ë””ì˜¤ ì²˜ë¦¬ (ê¸°ì¡´ ë°©ì‹)
        for video_path in args.videos:
            print(f"â–¶ Processing video: {video_path}")
            app.run_video(video_path)
        
        # ì„±ëŠ¥ ìš”ì•½ ì¶œë ¥ (ë‹¨ì¼ ë¹„ë””ì˜¤ì˜ ê²½ìš°)
        if app.thread_performance_loggers:
            for camera_id, thread_logger in app.thread_performance_loggers.items():
                print(f"\nğŸ“Š Camera {camera_id} Performance Summary:")
                thread_logger.print_summary()
        else:
            print("ğŸ“Š No performance data available")


if __name__ == '__main__':
    main()
