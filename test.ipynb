{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bf482573",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jeongseungbin/Desktop/kseb_project/smart-factory-peaceeye/deep-person-reid-master/torchreid/metrics/rank.py:11: UserWarning: Cython evaluation (very fast so highly recommended) is unavailable, now use python evaluation.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import json\n",
    "import torch\n",
    "import sys\n",
    "import threading\n",
    "import numpy as np\n",
    "import argparse\n",
    "import queue\n",
    "from ultralytics import YOLO\n",
    "from scipy.spatial.distance import cdist\n",
    "\n",
    "# --- 경로 설정 ---\n",
    "# 현재 스크립트의 위치를 기준으로 상대 경로를 설정하여 다른 환경에서의 실행을 용이하게 합니다.\n",
    "try:\n",
    "    # ByteTrack, deep-person-reid가 현재 프로젝트 폴더 내에 있다고 가정\n",
    "    sys.path.append('ByteTrack')\n",
    "    sys.path.append('deep-person-reid-master')\n",
    "    # sys.path.append('TensorRT-8.5.3.1')\n",
    "    from yolox.tracker.byte_tracker import BYTETracker, STrack as OriginalSTrack, TrackState\n",
    "    from yolox.tracker.kalman_filter import KalmanFilter\n",
    "    from yolox.tracker.matching import iou_distance, linear_assignment\n",
    "    from torchreid.utils.feature_extractor import FeatureExtractor\n",
    "    # import tensorrt as trt\n",
    "except ImportError as e:\n",
    "    print(f\"필수 라이브러리 로드 실패: {e}\")\n",
    "    print(\"ByteTrack 또는 deep-person-reid 경로를 확인하거나 'pip install -r requirements.txt'를 실행하세요.\")\n",
    "    sys.exit(1)\n",
    "\n",
    "\n",
    "\n",
    "# --- np.float 호환성 문제 해결 ---\n",
    "# numpy 1.24.0 이상 버전에서 np.float이 제거됨에 따라 float으로 대체합니다.\n",
    "if not hasattr(np, 'float'):\n",
    "    np.float = float"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cfcdb9f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import threading\n",
    "from collections import deque\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "class CrossCameraReIDManager:\n",
    "    def __init__(self, similarity_threshold=0.7, feature_ttl=300):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            similarity_threshold: Re-ID 매칭 임계값\n",
    "            feature_ttl: 특징 벡터 유효 시간(초)\n",
    "        \"\"\"\n",
    "        self.features_db = {}  # {global_id: {'features': [], 'last_seen': datetime, 'cameras': set()}}\n",
    "        self.camera_to_global = {}  # {(camera_id, local_track_id): global_id}\n",
    "        self.lock = threading.Lock()\n",
    "        self.similarity_threshold = similarity_threshold\n",
    "        self.feature_ttl = feature_ttl\n",
    "        self.next_global_id = 1\n",
    "        \n",
    "    def match_or_create(self, camera_id, local_track_id, feature_vector, bbox_info):\n",
    "        \"\"\"\n",
    "        새로운 특징 벡터를 기존 DB와 비교하여 매칭하거나 새 ID 생성\n",
    "        \n",
    "        Returns:\n",
    "            global_id: 전역 추적 ID\n",
    "            is_new: 새로운 ID인지 여부\n",
    "        \"\"\"\n",
    "        with self.lock:\n",
    "            # 이미 매핑된 경우\n",
    "            if (camera_id, local_track_id) in self.camera_to_global:\n",
    "                global_id = self.camera_to_global[(camera_id, local_track_id)]\n",
    "                self._update_features(global_id, feature_vector, camera_id)\n",
    "                return global_id, False\n",
    "            \n",
    "            # 만료된 특징 벡터 정리\n",
    "            self._cleanup_expired_features()\n",
    "            \n",
    "            # 가장 유사한 기존 ID 찾기\n",
    "            best_match_id = None\n",
    "            best_similarity = 0\n",
    "            \n",
    "            for global_id, data in self.features_db.items():\n",
    "                # 같은 카메라에서 이미 추적 중인 ID는 제외\n",
    "                if camera_id in data['cameras']:\n",
    "                    continue\n",
    "                    \n",
    "                similarity = self._calculate_similarity(feature_vector, data['features'])\n",
    "                if similarity > self.similarity_threshold and similarity > best_similarity:\n",
    "                    best_match_id = global_id\n",
    "                    best_similarity = similarity\n",
    "            \n",
    "            if best_match_id:\n",
    "                # 기존 ID와 매칭\n",
    "                self.camera_to_global[(camera_id, local_track_id)] = best_match_id\n",
    "                self._update_features(best_match_id, feature_vector, camera_id)\n",
    "                return best_match_id, False\n",
    "            else:\n",
    "                # 새로운 전역 ID 생성\n",
    "                new_global_id = self.next_global_id\n",
    "                self.next_global_id += 1\n",
    "                \n",
    "                self.features_db[new_global_id] = {\n",
    "                    'features': deque([feature_vector], maxlen=10),  # 최근 10개 특징만 유지\n",
    "                    'last_seen': datetime.now(),\n",
    "                    'cameras': {camera_id},\n",
    "                    'first_bbox': bbox_info\n",
    "                }\n",
    "                self.camera_to_global[(camera_id, local_track_id)] = new_global_id\n",
    "                return new_global_id, True\n",
    "    \n",
    "    def _update_features(self, global_id, feature_vector, camera_id):\n",
    "        \"\"\"특징 벡터 업데이트\"\"\"\n",
    "        self.features_db[global_id]['features'].append(feature_vector)\n",
    "        self.features_db[global_id]['last_seen'] = datetime.now()\n",
    "        self.features_db[global_id]['cameras'].add(camera_id)\n",
    "    \n",
    "    def _calculate_similarity(self, query_feature, feature_list):\n",
    "        \"\"\"코사인 유사도 계산 (평균 특징 벡터 사용)\"\"\"\n",
    "        if not feature_list:\n",
    "            return 0\n",
    "        \n",
    "        # 최근 특징 벡터들의 평균 계산\n",
    "        avg_feature = np.mean(list(feature_list), axis=0)\n",
    "        avg_feature /= np.linalg.norm(avg_feature)\n",
    "        query_feature = query_feature / np.linalg.norm(query_feature)\n",
    "        \n",
    "        return np.dot(query_feature, avg_feature)\n",
    "    \n",
    "    def _cleanup_expired_features(self):\n",
    "        \"\"\"만료된 특징 벡터 제거\"\"\"\n",
    "        current_time = datetime.now()\n",
    "        expired_ids = []\n",
    "        \n",
    "        for global_id, data in self.features_db.items():\n",
    "            if (current_time - data['last_seen']).seconds > self.feature_ttl:\n",
    "                expired_ids.append(global_id)\n",
    "        \n",
    "        for global_id in expired_ids:\n",
    "            # 관련 매핑 제거\n",
    "            keys_to_remove = [(cam, track) for (cam, track), gid in self.camera_to_global.items() if gid == global_id]\n",
    "            for key in keys_to_remove:\n",
    "                del self.camera_to_global[key]\n",
    "            del self.features_db[global_id]\n",
    "    \n",
    "    def remove_track(self, camera_id, local_track_id):\n",
    "        \"\"\"특정 카메라의 트랙 제거\"\"\"\n",
    "        with self.lock:\n",
    "            if (camera_id, local_track_id) in self.camera_to_global:\n",
    "                global_id = self.camera_to_global[(camera_id, local_track_id)]\n",
    "                del self.camera_to_global[(camera_id, local_track_id)]\n",
    "                \n",
    "                # 해당 카메라 제거\n",
    "                if global_id in self.features_db:\n",
    "                    self.features_db[global_id]['cameras'].discard(camera_id)\n",
    "                    \n",
    "                    # 더 이상 추적하는 카메라가 없으면 일정 시간 후 자동 삭제됨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4e531f50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 개선된 STrack 클래스 ---\n",
    "class STrack(OriginalSTrack):\n",
    "    \"\"\"\n",
    "    기존 STrack을 상속받아 ReID 특징(feature)을 관리하고,\n",
    "    시간이 지나도 안정적인 특징 유지를 위해 feature smoothing을 추가합니다.\n",
    "    \"\"\"\n",
    "    def __init__(self, tlwh, score, *args, **kwargs):\n",
    "        super().__init__(tlwh, score, *args, **kwargs)\n",
    "        self.smooth_feat = None\n",
    "        self.curr_feat = None\n",
    "        self.alpha = 0.9  # Feature smoothing factor (이전 feature를 얼마나 유지할지 결정)\n",
    "\n",
    "    def update_features(self, feat):\n",
    "        \"\"\"새로운 ReID feature로 현재 feature를 업데이트하고, smoothing을 적용합니다.\"\"\"\n",
    "        feat /= np.linalg.norm(feat)  # L2 정규화\n",
    "        self.curr_feat = feat\n",
    "        if self.smooth_feat is None:\n",
    "            self.smooth_feat = feat\n",
    "        else:\n",
    "            # 지수 이동 평균(Exponential Moving Average)과 유사한 방식으로 feature를 부드럽게 업데이트\n",
    "            self.smooth_feat = self.alpha * self.smooth_feat + (1 - self.alpha) * feat\n",
    "        self.smooth_feat /= np.linalg.norm(self.smooth_feat)\n",
    "\n",
    "    @staticmethod\n",
    "    def multi_predict(stracks, kalman_filter):\n",
    "        \"\"\"Kalman Filter를 사용해 여러 트랙의 다음 상태를 예측합니다.\"\"\"\n",
    "        if len(stracks) > 0:\n",
    "            multi_mean = np.asarray([st.mean.copy() for st in stracks])\n",
    "            multi_covariance = np.asarray([st.covariance.copy() for st in stracks])\n",
    "            multi_mean, multi_covariance = kalman_filter.multi_predict(multi_mean, multi_covariance)\n",
    "            for i, st in enumerate(stracks):\n",
    "                st.mean = multi_mean[i]\n",
    "                st.covariance = multi_covariance[i]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0266f084",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- ReID와 IOU를 함께 사용하는 개선된 BYTETracker ---\n",
    "class BYTETrackerWithReID(BYTETracker):\n",
    "    \"\"\"\n",
    "    기존 BYTETracker의 update 로직을 ReID feature를 사용하도록 개선합니다.\n",
    "    Cascaded Matching(단계적 매칭)을 통해 정확도를 높입니다.\n",
    "    1. IOU 기반 매칭: 확실한 트랙들을 먼저 연결합니다.\n",
    "    2. Re-ID 기반 매칭: IOU로 찾지 못한 트랙(가려짐 등)을 외형 특징으로 다시 찾아 연결합니다.\n",
    "    \"\"\"\n",
    "    def __init__(self, args, frame_rate=30):\n",
    "        super().__init__(args, frame_rate)\n",
    "        self.reid_thresh = 0.6  # Re-ID 코사인 거리 임계값 (1 - 유사도)\n",
    "\n",
    "    def update(self, dets, img_info, img, reid_extractor):\n",
    "        self.frame_id += 1\n",
    "        activated_stracks = []\n",
    "        refind_stracks = []\n",
    "        lost_stracks = []\n",
    "        removed_stracks = []\n",
    "\n",
    "        # 1. 감지된 객체(dets) 전처리\n",
    "        scores = dets[:, 4]\n",
    "        bboxes = dets[:, :4]\n",
    "        \n",
    "        # 신뢰도 임계값(track_thresh) 이상의 객체만 'detections'으로 간주\n",
    "        remain_inds = scores > self.args.track_thresh #임계값 보다높은 애들은 True인 boolean 배열로 변경\n",
    "        high_conf_dets = bboxes[remain_inds] #boolean배열을 적용하여 True만 필터링\n",
    "        high_conf_scores = scores[remain_inds] \n",
    "        \n",
    "        if high_conf_dets.shape[0] > 0:\n",
    "            # 이미지에서 객체 부분만 잘라내 Re-ID 특징 추출\n",
    "            crops = []\n",
    "            for box in high_conf_dets:\n",
    "                x1, y1, x2, y2 = map(int, box)\n",
    "                crop = img[y1:y2, x1:x2]\n",
    "                if crop.size == 0: # 크기가 0인 crop 방지\n",
    "                    crop = np.zeros((128, 64, 3), dtype=np.uint8) #크기가 0이면 오류가 나지 않게 더미 이미지 생성\n",
    "                crops.append(crop)\n",
    "            \n",
    "            features = reid_extractor(crops).cpu().numpy() #크롭 이미지를 넘겨주면 Re-ID모델이 벡터로 변환  (현재프레임에서 탐지된 신뢰도 높은 사람의 수, 벡터-512차원)\n",
    "            detections = [STrack(STrack.tlbr_to_tlwh(tlbr), s) for tlbr, s in zip(high_conf_dets, high_conf_scores)] # 두개를 STrack 객체리스트로 한번에 변환 (바운딩 박스와 신뢰도 매칭)\n",
    "                            #yolo는 tlbr형식 topleft,bottomright -> topleft, width, height\n",
    "            for d, f in zip(detections, features): #리스트에서 하나씩 꺼내서 반복\n",
    "                d.update_features(f) #STrack객체에 특징벡터를 전달\n",
    "        else:\n",
    "            detections = []\n",
    "\n",
    "        # 2. 기존 트랙과 새로 감지된 객체 매칭 준비\n",
    "        unconfirmed = []\n",
    "        tracked_stracks = []\n",
    "        for track in self.tracked_stracks:\n",
    "            if not track.is_activated: #탐지된지 얼마 되지 않아 아직 신뢰할 수 없는 임시 트랙\n",
    "                unconfirmed.append(track)\n",
    "            else:\n",
    "                tracked_stracks.append(track)\n",
    "        \n",
    "        # 추적 중인 트랙과 최근에 잃어버린 트랙을 합쳐 매칭 대상(pool)으로 설정\n",
    "        strack_pool = joint_stracks(tracked_stracks, self.lost_stracks) #하나의 리스트로\n",
    "        STrack.multi_predict(strack_pool, self.kalman_filter) #strackpool에 있는 모든 트랙에 대해 칼만필터의 예측을 한번에 진행\n",
    "\n",
    "        # 3. 단계적 매칭 (Cascaded Matching)\n",
    "        # 3-1. IOU 거리 기반 1차 매칭 (가깝고 확실한 경우)\n",
    "        dists = iou_distance(strack_pool, detections)\n",
    "        matches, u_track, u_detection = linear_assignment(dists, thresh=self.args.match_thresh) #매치o, 매치x, 매치x 매트릭스에서 cost가 가장낮은걸 매칭\n",
    "\n",
    "        for itracked, idet in matches:\n",
    "            track = strack_pool[itracked]\n",
    "            det = detections[idet] #현재 프레임에서 새로 발견된 객체 정보\n",
    "            if track.state == TrackState.Tracked: #추적되고 있던 객체는 위치만 업데이트\n",
    "                track.update(det, self.frame_id) #현재 프레임 정보를 넘겨주어 몇번째 프레임에서 다시 찾았는지 기록\n",
    "                activated_stracks.append(track)\n",
    "            else: # Lost 상태의 트랙을 다시 찾은 경우\n",
    "                track.re_activate(det, self.frame_id, new_id=False) #track의 상태를 TrackState.Lost에서 다시 TrackState.Tracked로 변경\n",
    "                refind_stracks.append(track) #new_id=False 이 객체에 새로운 ID를 부여하지 말고 track이 원래 가지고 있던 기존 ID그대로 사용\n",
    "\n",
    "        # 3-2. Re-ID 특징 기반 2차 매칭 (가려졌거나 멀리 떨어진 경우)\n",
    "        # 1차 매칭에서 실패한 '잃어버린 트랙(lost tracks)'과 '감지된 객체'를 대상으로 수행\n",
    "        lost_pool = [strack_pool[i] for i in u_track if strack_pool[i].state == TrackState.Lost]\n",
    "        remaining_detections = [detections[i] for i in u_detection]\n",
    "\n",
    "        if len(lost_pool) > 0 and len(remaining_detections) > 0:\n",
    "            lost_features = np.array([track.smooth_feat for track in lost_pool])\n",
    "            det_features = np.array([det.smooth_feat for det in remaining_detections])\n",
    "            \n",
    "            # 코사인 거리 계산\n",
    "            feature_dists = cdist(lost_features, det_features, 'cosine')\n",
    "            reid_matches, u_lost, u_det_reid = linear_assignment(feature_dists, thresh=self.reid_thresh) #매치o, 매치x, 매치x 매트릭스에서 cost가 가장낮은걸 매칭\n",
    "\n",
    "            for ilost, idet in reid_matches: #reid_matches는 성공적으로 짝지어진 쌍들의 목록으로 매칭된 쌍들을 하나씩 둘러봄\n",
    "                track = lost_pool[ilost] # lost 상태의 STrack객체를 가져옴\n",
    "                det = remaining_detections[idet] # 새로 탐지된 객체를 가져옴\n",
    "                track.re_activate(det, self.frame_id, new_id=False) #새로 탐지된 위치로 최신화\n",
    "                refind_stracks.append(track)\n",
    "        \n",
    "        # Re-ID로 매칭된 객체는 u_detection에서 제거해야 하지만, 복잡성을 줄이기 위해 생략.\n",
    "        # 이로 인해 일부 객체가 중복 처리될 수 있으나, 전체적인 성능에 큰 영향은 없음.\n",
    "\n",
    "        # 4. 나머지 트랙 처리 및 새로운 트랙 생성\n",
    "        # 매칭 안된애들\n",
    "        remaining_tracked_pool = [strack_pool[i] for i in u_track if strack_pool[i].state == TrackState.Tracked]\n",
    "        for track in remaining_tracked_pool:\n",
    "            track.mark_lost()\n",
    "            lost_stracks.append(track)\n",
    "\n",
    "        # 매칭되지 않은 높은 신뢰도의 객체는 새로운 트랙으로 등록\n",
    "        for i in u_detection:\n",
    "            track = detections[i]\n",
    "            if track.score >= self.args.track_thresh: #기존에 id와 매칭되지 않은 높은 신뢰도의 객체는 새로운 id를 부여해 트랙에 등록\n",
    "                track.activate(self.kalman_filter, self.frame_id)\n",
    "                activated_stracks.append(track)\n",
    "\n",
    "        # 5. 최종 트랙 리스트 정리\n",
    "        self.tracked_stracks = [t for t in self.tracked_stracks if t.state == TrackState.Tracked]\n",
    "        self.tracked_stracks = joint_stracks(self.tracked_stracks, activated_stracks) #이번에 새로 activate된 Strack\n",
    "        self.tracked_stracks = joint_stracks(self.tracked_stracks, refind_stracks) # 재활성화된 Strack. #self.tarcked_stracks 이번프레임 기준으로 살아있는 모든 트랙 최신화\n",
    "        self.lost_stracks = sub_stracks(self.lost_stracks, self.tracked_stracks)\n",
    "        self.lost_stracks.extend(lost_stracks) # 너무 오래 lost상태여서 제거하는 strack\n",
    "        self.lost_stracks = sub_stracks(self.lost_stracks, self.removed_stracks)  #메모리 누수를 막기 위한 장치 \n",
    "        self.removed_stracks.extend(self.lost_stracks) # 메모리 정리 로직 (단순화)\n",
    "        \n",
    "        self.tracked_stracks, self.lost_stracks = remove_duplicate_stracks(self.tracked_stracks, self.lost_stracks)\n",
    "        \n",
    "        return [t for t in self.tracked_stracks if t.is_activated]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "df1f9d83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 유틸리티 함수 ---\n",
    "def joint_stracks(tlista, tlistb):\n",
    "    exists = {t.track_id for t in tlista}\n",
    "    res = tlista[:]\n",
    "    for t in tlistb:\n",
    "        if t.track_id not in exists:\n",
    "            exists.add(t.track_id)\n",
    "            res.append(t)\n",
    "    return res\n",
    "\n",
    "def sub_stracks(tlista, tlistb):\n",
    "    track_ids_b = {t.track_id for t in tlistb}\n",
    "    return [t for t in tlista if t.track_id not in track_ids_b]\n",
    "\n",
    "def remove_duplicate_stracks(stracks1, stracks2):\n",
    "    pdist = iou_distance(stracks1, stracks2)\n",
    "    pairs = np.where(pdist < 0.15)\n",
    "    dupa, dupb = list(pairs[0]), list(pairs[1])\n",
    "    for p, q in zip(dupa, dupb):\n",
    "        timep = stracks1[p].frame_id - stracks1[p].start_frame\n",
    "        timeq = stracks2[q].frame_id - stracks2[q].start_frame\n",
    "        if timep > timeq:\n",
    "            stracks2[q].state = TrackState.Removed\n",
    "    return stracks1, stracks2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ef62cfdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_tracking(video_path, yolo_model_path, reid_extractor, frame_queue, stop_event, reid_manager):\n",
    "    \"\"\"Cross-camera Re-ID가 추가된 추적 함수\"\"\"\n",
    "    model = YOLO(yolo_model_path, task=\"detect\")\n",
    "    classNames = model.names\n",
    "    camera_id = cli_args.videos.index(video_path)  # 카메라 ID\n",
    "\n",
    "    tracker_args = argparse.Namespace(track_thresh=0.5, match_thresh=0.8, track_buffer=150, mot20=False)\n",
    "    tracker = BYTETrackerWithReID(tracker_args, frame_rate=30)\n",
    "\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    local_to_global_map = {}  # 로컬 ID -> 전역 ID 매핑\n",
    "\n",
    "    while cap.isOpened() and not stop_event.is_set():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        # 프레임 처리 (기존 코드와 동일)\n",
    "        frame_height, frame_width = frame.shape[:2]\n",
    "        target_width = 640\n",
    "        scale = target_width / frame_width\n",
    "        target_height = int(frame_height * scale)\n",
    "        frame = cv2.resize(frame, (target_width, target_height))\n",
    "\n",
    "        detection_results = model(frame, verbose=False, half=torch.cuda.is_available())[0]\n",
    "        dets = []\n",
    "        for box in detection_results.boxes:\n",
    "            cls_id = int(box.cls[0])\n",
    "            conf = float(box.conf[0])\n",
    "            if classNames[cls_id].lower() in [\"person\", \"persona\"]:\n",
    "                x1, y1, x2, y2 = box.xyxy[0].tolist()\n",
    "                dets.append([x1, y1, x2, y2, conf])\n",
    "\n",
    "        if len(dets) > 0:\n",
    "            online_targets = tracker.update(torch.tensor(dets), frame.shape[:2], frame, reid_extractor)\n",
    "            \n",
    "            frame_detections_json = []\n",
    "            for t in online_targets:\n",
    "                local_id = t.track_id\n",
    "                \n",
    "                # Cross-camera Re-ID 수행\n",
    "                bbox_info = {\n",
    "                    'camera_id': camera_id,\n",
    "                    'bbox': t.tlbr.tolist(),\n",
    "                    'timestamp': datetime.now()\n",
    "                }\n",
    "                \n",
    "                global_id, is_new = reid_manager.match_or_create(\n",
    "                    camera_id, \n",
    "                    local_id, \n",
    "                    t.smooth_feat,  # 안정화된 특징 벡터 사용\n",
    "                    bbox_info\n",
    "                )\n",
    "                \n",
    "                # 로컬-전역 ID 매핑 저장\n",
    "                local_to_global_map[local_id] = global_id\n",
    "                \n",
    "                xmin, ymin, xmax, ymax = map(int, t.tlbr)\n",
    "                point_x = (xmin + xmax) / 2\n",
    "                point_y = ymin\n",
    "                \n",
    "                detection_data = {\n",
    "                    \"camera_id\": camera_id,\n",
    "                    \"local_track_id\": int(local_id),\n",
    "                    \"global_track_id\": int(global_id),  # 전역 ID 추가\n",
    "                    \"bbox_xyxy\": [point_x, point_y],\n",
    "                    \"is_new_global\": is_new\n",
    "                }\n",
    "                frame_detections_json.append(detection_data)\n",
    "\n",
    "                # 화면에 전역 ID 표시\n",
    "                cv2.rectangle(frame, (xmin, ymin), (xmax, ymax), (0, 255, 0), 2)\n",
    "                cv2.putText(frame, f'G:{global_id} L:{local_id}', \n",
    "                           (xmin, ymin - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 0), 2)\n",
    "\n",
    "            if frame_detections_json:\n",
    "                print(f\"--- Camera {camera_id} ({video_path}) ---\")\n",
    "                print(json.dumps(frame_detections_json, indent=2))\n",
    "\n",
    "        frame_queue.put((video_path, frame))\n",
    "\n",
    "    # 추적 종료된 ID들 정리\n",
    "    for local_id in local_to_global_map:\n",
    "        reid_manager.remove_track(camera_id, local_id)\n",
    "    \n",
    "    cap.release()\n",
    "    frame_queue.put((video_path, None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1c3f0af1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(args):\n",
    "    reid_extractor = FeatureExtractor(\n",
    "        model_name='osnet_ibn_x1_0',\n",
    "        model_path=args.reid_model if args.reid_model else None,\n",
    "        device='cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    )\n",
    "    \n",
    "    # Cross-camera Re-ID 매니저 생성\n",
    "    reid_manager = CrossCameraReIDManager(\n",
    "        similarity_threshold=0.65,  # 임계값 조정 필요\n",
    "        feature_ttl=300  # 5분간 특징 벡터 유지\n",
    "    )\n",
    "    \n",
    "    frame_queue = queue.Queue()\n",
    "    stop_event = threading.Event()\n",
    "    \n",
    "    threads = []\n",
    "    for video_path in args.videos:\n",
    "        thread = threading.Thread(\n",
    "            target=run_tracking, \n",
    "            args=(video_path, args.yolo_model, reid_extractor, frame_queue, stop_event, reid_manager),\n",
    "            daemon=True\n",
    "        )\n",
    "        threads.append(thread)\n",
    "        thread.start()\n",
    "\n",
    "    # 이하 동일...\n",
    "\n",
    "    latest_frames = {}\n",
    "    active_videos = set(args.videos)\n",
    "\n",
    "    while active_videos:\n",
    "        try:\n",
    "            # 큐에서 프레임 가져오기 (타임아웃을 사용하여 GUI가 멈추지 않도록 함)\n",
    "            video_path, frame = frame_queue.get(timeout=0.1)\n",
    "\n",
    "            if frame is None:  # 스레드 종료 신호\n",
    "                active_videos.discard(video_path)\n",
    "                if video_path in latest_frames:\n",
    "                    del latest_frames[video_path]\n",
    "                cv2.destroyWindow(f\"Tracking - {video_path}\")\n",
    "                continue\n",
    "            \n",
    "            latest_frames[video_path] = frame\n",
    "\n",
    "        except queue.Empty:\n",
    "            # 큐가 비어있으면 현재 프레임들을 다시 그림\n",
    "            pass\n",
    "\n",
    "        # 모든 활성 비디오의 최신 프레임을 화면에 표시\n",
    "        for path, f in latest_frames.items():\n",
    "            cv2.imshow(f\"Tracking - {path}\", f)\n",
    "\n",
    "        # 'q'를 누르면 모든 스레드에 종료 신호를 보내고 루프 탈출\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            stop_event.set()\n",
    "            break\n",
    "    \n",
    "    # 모든 스레드가 정상적으로 종료될 때까지 대기\n",
    "    for thread in threads:\n",
    "        thread.join()\n",
    "\n",
    "    cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "83c41e35",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: ipykernel_launcher.py [-h] [--videos VIDEOS [VIDEOS ...]]\n",
      "                             [--yolo_model YOLO_MODEL]\n",
      "                             [--reid_model REID_MODEL]\n",
      "ipykernel_launcher.py: error: unrecognized arguments: --f=/Users/jeongseungbin/Library/Jupyter/runtime/kernel-v3974a24b995d30d393045fd8afa7fcc7740b03a7f.json\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[31mSystemExit\u001b[39m\u001b[31m:\u001b[39m 2\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    parser = argparse.ArgumentParser(description=\"YOLOv8 with ByteTrack and Re-ID for Multi-Video Tracking\")\n",
    "    parser.add_argument('--videos', nargs='+', type=str, default=[\"test_video/test01.mp4\",\"test_video/0_te2.mp4\"], help='List of video file paths.')\n",
    "    parser.add_argument('--yolo_model', type=str, default=\"models/weights/best.pt\", help='Path to the YOLOv11 model file.')\n",
    "    parser.add_argument('--reid_model', type=str, default=\"\", help='Path to the Re-ID model weights. Leave empty to download pretrained.')\n",
    "    \n",
    "    cli_args = parser.parse_args()\n",
    "    main(cli_args)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
