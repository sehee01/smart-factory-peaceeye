# ai/run_yolo_test.py
"""
YOLOv8 sanity-check script
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
â€¢ ê¸°ë³¸ ê°€ì¤‘ì¹˜ ê²½ë¡œ : ai/weights/best.pt
â€¢ ë‹¨ì¼ ì´ë¯¸ì§€ / í´ë” / ë™ì˜ìƒ / ì›¹ìº  ìŠ¤íŠ¸ë¦¼ì„ ëª¨ë‘ ì²˜ë¦¬
â€¢ --save ì˜µì…˜ì„ ì£¼ë©´ ai/output/ ì— ë°”ìš´ë”©ë°•ìŠ¤ê°€ ê·¸ë ¤ì§„ ê²°ê³¼ ì €ì¥
"""

from pathlib import Path
import argparse, sys, subprocess, json
import torch
from ultralytics import YOLO

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
ROOT = Path(__file__).resolve().parents[1]          # smartfactoryPeaceeye/
DEFAULT_WEIGHTS = ROOT / "weights" / "best.pt"
DEFAULT_OUTDIR  = ROOT / "ai" / "output"
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def parse_args() -> argparse.Namespace:
    p = argparse.ArgumentParser()
    p.add_argument("--source", required=True,
                   help="ì´ë¯¸ì§€/í´ë”/ë™ì˜ìƒ ê²½ë¡œ ë˜ëŠ” ì›¹ìº  ì¸ë±ìŠ¤(0,1,...)")
    p.add_argument("--weights", type=Path, default=DEFAULT_WEIGHTS,
                   help=f"YOLO .pt (default: {DEFAULT_WEIGHTS})")
    p.add_argument("--device", default="cuda",
                   help="'cuda', GPU ë²ˆí˜¸(0|1|...), or 'cpu'")
    p.add_argument("--save", action="store_true",
                   help="ê²°ê³¼ë¥¼ ai/output/ì— ì €ì¥")
    return p.parse_args()

def check_cuda(device_flag: str):
    if device_flag != "cpu" and not torch.cuda.is_available():
        sys.exit("âŒ GPU(CUDA)ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. --device cpu ë¡œ ì‹¤í–‰í•˜ì„¸ìš”.")

def main():
    args = parse_args()
    check_cuda(args.device)

    print(f"ğŸŸ¢ Loading model : {args.weights}")
    print(f"ğŸŸ¢ Device        : {args.device}")

    model = YOLO(str(args.weights))
    model.to(args.device)

    outdir = None
    if args.save:
        outdir = model.predict(
            args.source,
            save=True,
            project=str(DEFAULT_OUTDIR),
            name="run"
        )[0].save_dir
    else:
        model.predict(args.source, save=False)

    print("âœ… Inference finished.")

    if outdir:
        print(f"ğŸ“‚ Saved to : {outdir}")

if __name__ == "__main__":
    main()
